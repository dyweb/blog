[{"content":"\n\nSuppose we would like to perform a task repeatedly at regular intervals with a goroutine.\n\nHere is the first try:\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"time\"\n)\n\nfunc main() {\n\tgo func() {\n\t\tfor {\n\t\t\tfmt.Println(\"hello, world!\")\n\t\t\ttime.Sleep(5 * time.Second)\n\t\t}\n\t}()\n}\n```\n\nOops, it does not work. The main function terminates immediately after starting the goroutine,\nand the program terminates with the termination of the main function.\n\nWe should let the main function wait for the goroutine. Therefore,\n[WaitGroup](https://golang.org/pkg/sync/#WaitGroup) is needed.\n\n```go\npackage main\n\nimport (\n\t\"fmt\"\n\t\"sync\"\n\t\"time\"\n)\n\ntype WaitGroupWrapper struct {\n\twg sync.WaitGroup\n}\n\nfunc (w *WaitGroupWrapper) Spawn(f func()) {\n\tw.wg.Add(1)\n\tgo func() {\n\t\tf()\n\t\tw.wg.Done()\n\t}()\n}\n\nfunc (w *WaitGroupWrapper) Wait() {\n\tw.wg.Wait()\n}\n\nfunc main() {\n\tvar wg WaitGroupWrapper\n\twg.Spawn(func() {\n\t\tfor {\n\t\t\tfmt.Println(\"hello, world!\")\n\t\t\ttime.Sleep(5 * time.Second)\n\t\t}\n\t})\n\twg.Wait()\n}\n```\n\nNote that I used a wrapper to wrap the WaitGroup to make it easier to use.\nNow the program works, but we can improve it with tickers, which provide by\nGo for doing something repeatedly at regular intervals.\n\n```go\nticker := time.NewTicker(5 * time.Second)\nwg.Spawn(func() {\n    for {\n        \u003c-ticker.C\n        fmt.Println(\"hello, world!\")\n    }\n})\n```\n\nCurrently, our goroutine runs forever. We can stop it using another channel.\n\n```go\nfunc main() {\n\tvar wg WaitGroupWrapper\n\tdone := make(chan struct{})\n\tticker := time.NewTicker(5 * time.Second)\n\twg.Spawn(func() {\n\t\tfor {\n\t\t\tselect {\n\t\t\tcase \u003c-ticker.C:\n\t\t\t\tfmt.Println(\"hello, world!\")\n\t\t\tcase \u003c-done:\n\t\t\t\tgoto exit\n\t\t\t}\n\t\t}\n\texit:\n\t})\n\ttime.Sleep(16 * time.Second)\n\tclose(done)\n\twg.Wait()\n}\n```\n\n## License\n\n- This article is licensed under [CC BY-NC-SA 3.0](https://creativecommons.org/licenses/by-nc-sa/3.0/).\n- Please contact \u003cmarketing@dongyue.io\u003e for commerical use.\n","cover":"","link":"go:_tasks_repeated_at_intervals.html","preview":"\u003cp\u003eUse Go to run tasks at intervals.\u003c/p\u003e\n","title":"Go: tasks repeated at intervals"},{"content":"\n\n[@codeworm96]: https://github.com/codeworm96\n[@hawkingrei]: https://github.com/hawkingrei\n[@prism-river]: https://github.com/prism-river\n[Killy]: https://github.com/prism-river/killy\n\n2017 年 10 月 21 日，由 [Golang Foundation](http://golangfoundation.org/) 和 [PingCAP](https://pingcap.com/index) 联合举办的 [Go Hack 17](http://gohack2017.golangfoundation.org/) 在上海心动网络举行，东岳的小哥哥 [@gaocegege](https://github.com/gaocegege) 和 [@codeworm96][]，以及工作一年的 Go 工程师 [@hawkingrei][] 一起组成了队伍 ，参加了这次 hackathon，凭借 [killy: Play TiDB in Minecraft!](https://github.com/prism-river/killy) 取得了二等奖以及 PingCAP 赞助的专项奖。这篇文章是 [@gaocegege](https://github.com/gaocegege) 第一人称视角的 hackathon 记录。\n\n## 好名字是成功的一半\n\n先从开头说起，最开始，是从 TiDB Contributor 的微信群中，看到了 PingCAP 小狼发的链接，知道了这个 hackathon。因为之前 hackathon 中的一些不好的体验，所以当时对是否参加这个比赛还是持观望态度。但是考虑到自己马上就要毕业了，需要多多地接触公司为一年后的实习还有两年后的工作做一些铺垫，在赞助公司里有好多是自己比较感兴趣的公司，于是拉拢了与我同在软院的大四学弟 [@codeworm96][] 和之前在 [Processing.R](https://github.com/gaocegege/Processing.R) 项目上有过合作的 Go 工程师 [@hawkingrei][] 组队报名了。\n\n在报名的时候，组织方要我们提交项目名和队名，于是我们提交了两个特别二次元的名字。团队的名字“Prismriver”是 [@codeworm96][] 学弟起的，是 [东方 Project 里的三姐妹](https://zh.moegirl.org/%E8%8E%89%E8%8E%89%E5%8D%A1%C2%B7%E6%99%AE%E8%8E%89%E5%85%B9%E5%A7%86%E5%88%A9%E5%B7%B4)。项目的名字“Killy”是 [@hawkingrei][] 提出的，一部硬科幻的男主的名字，据他说男主挺帅的。当时想着反正之后做项目可以改，并没有什么关系。但是后来开始之后也就没那么多闲心去想名字了，索性一直沿用到最后。而因为在 GitHub 上创建 organization 的时候我忘了 Prismriver 是连在一起的还是分开的，错误地使用了 prism-river，Go 对项目的路径是有要求的，直接改动组织名会造成很多麻烦的事情，所以现在在 GitHub 上我们的名字是 [@prism-river][]。\n\n## Idea 是成功的一半的一半\n\n定下了名字，开始想 idea。在石墨文档上记录着我们当时所有想到的 idea，一共有十二个。[@hawkingrei][] 工作了一年多，想到的很多 idea 是跟他的日常工作息息相关的，都是一些可以解决他的痛点的小 idea。因为我之前做过容器和持续集成方面的工作，因此想到的多是跟 Docker 或者 CI 有关系，偶尔有一些跟 TiDB 搭点边，下面的截图是我们想到一部分 idea。\n\n\u003cfigure\u003e\n\t\u003cimg src=\"/images/posts/killy/idea.png\" alt=\"Ideas\"\u003e\n\u003c/figure\u003e\n\n在所有的 idea 中，我们确定了两个候选 idea，按照意愿排序是 TiDBcraft 和 Local Travis Runner Based on Docker。后者是我在实现 [caicloud/cyclone](https://github.com/caicloud/cyclone) 的过程中想到的一个工具。在日常的生活中，我比较常用的 CI 工具是 Travis CI，而因为在很多公司里用的多的还是 Jenkins。所以我在想怎么能把 Travis CI 的 build 放在 Jenkins 里跑，一种比较简单的做法，就是保留 Travis CI 的配置，根据配置运行一个容器，把容器放在 Jenkins 的 build 中去跑。Travis CI 自身的设计使得这样的实现变得非常简单，因为它们有专门的一个组件是做 `.travis.yml -\u003e build.sh` 的转换的，得到 bash 脚本之后，放到 Travis CI 对应语言的官方镜像里去跑就好了。通过这样的实现，只要 repo 里有 .travis.yml 配置文件，就可以在任何支持 Docker 的 CI 工具中去运行。\n\nTiDBcraft 就是我们后来决定实现的 [Killy][]，最初的 idea 来自于之前写的 [dronecraft](https://github.com/gaocegege/dronecraft)，而 [dronecraft](https://github.com/gaocegege/dronecraft) 是受 [dockercraft](https://github.com/docker/dockercraft) 启发。我们想在 Minecraft 中监视整个 TiDB 集群的状态，以及其中表的状态，等等，这可以理解为是一个 Minecraft 里的 TiDB Dashboard。这只是一个概念，在未来甚至可以把整个物理机房都建模在 Minecraft 里，再配合 HoloLens，就可以实现 VR 运维了 /w\\\n\n最后在这两个里投票选一个做的时候，是挺纠结的，最后是 [@codeworm96][] 更倾向于 Just for Fun，于是就拍定了做 TiDBcraft。\n\n\u003cfigure\u003e\n\t\u003cimg src=\"/images/posts/killy/record.jpg\" alt=\"Record\" height=\"500\"\u003e\n\u003c/figure\u003e\n\n## 好的分工是成功的一半的一半的一半\n\n在介绍分工之前，先向大家介绍一下我们的架构。\n\n\u003cfigure\u003e\n\t\u003cimg src=\"https://github.com/prism-river/killy/raw/master/presentation/images/arch.png\" alt=\"Arch\" width=\"500\"\u003e\n\u003c/figure\u003e\n\nKilly 一共有两部分，前端与后端。前端是一个在 [Cuberite](https://cuberite.org/) 服务器中的插件。[Cuberite](https://cuberite.org/) 是一个用 C++ 实现的 Minecraft 服务器，支持使用 Lua 语言实现插件来扩展服务器功能，相信玩 Minecraft 的同学一定都接触过。后端是用 Go 实现的服务器，它负责从 TiDB 集群或者是 Prometheus 中定期拿到整个 TiDB 集群状态，然后转发给前端的插件，前端插件会将其绘制在 Minecraft 世界中，前后端通过一个 TCP 连接通信。整体的架构非常简单。\n\n比赛开始的周六，在 5 分钟内我们三个人就敲定了分工。由我来负责前端插件的实现，因为相对来说我对 Minecraft 比较熟悉而且之前也写过几十行 Lua，尽管我更想写 Go =。= [@codeworm96][] 和 [@hawkingrei][] 负责实现后端的逻辑。更具体来说，[@codeworm96][] 负责与数据库本身的交互，[@hawkingrei][] 负责跟整个集群交互获得集群实时的状态。\n\n## 完整的实现是成功的一半的一半的一半的一半\n\n第一天下午是我们精力最充沛的时候。这个时候我在构思并实现如何在 Minecraft 中显示数据库的表，而他们两个人在调研如何订阅 TiDB 中数据的变更和感知到整个集群的状态变更。对于前者我个人觉得 binlog 可能是可以用的，但是这样有点麻烦，不是在这个 hackathon 中适合的解决方案，所以提出直接暴力地轮询。在 [@codeworm96][] 认可后他开始着手实现，而我快速地实现了第一版 UI。在第一版中，有很多局限性，比如字段最多只支持 4 个，因为 Minecraft 里一个告示板只能显示 4 行。后来在晚上的时候，[@codeworm96][] 实现了第一版逻辑，暴力轮询数据库表然后转发给前端，然后我们进行了集成。而 [@hawkingrei][] 这时也实现了第一版，可以拿到所有 TiDB 集群上实例的静态信息。在晚上 12 点左右，我跟女朋友先走了，回去后，[@codeworm96][] 告诉我接受 SQL 查询的功能也实现了，于是我对接了这部分逻辑，实现了在 Minecraft Console 中执行 SQL 查询的功能，并且做了一个小 trick，把查到的记录高亮显示，就是原本是蓝色羊毛，查询到会变成绿色羊毛。\n\n\u003cfigure\u003e\n\t\u003cimg src=\"https://raw.githubusercontent.com/prism-river/killy/master/presentation/images/table.png\" alt=\"Table UI\" width=\"500\"\u003e\n\u003c/figure\u003e\n\n这些结束后，就选择了睡觉，这个时候大概是 1 点半，睡前与 [@hawkingrei][] 约定好三点起来。[@hawkingrei][] 在彻夜工作，在 3 点半的时候微信告诉我他负责的监控部分已经准备好了，因为 Prometheus 不能获得机器的实际状态，而且查询语句比较弱，有些功能短时间内实现比较难，所以方案换成了直接通过 TiKV，PD 的 REST API 拿到状态数据。可是这个时候我还没起来 =。=\n\n4 点 50 分的时候，我终于意识到再睡下去要背锅了，于是艰难地爬了起来。在 5 点 40 分的时候到了心动网络，从旁边的全家里买了一份三明治，走进了 hackathon 场地，发现大多数人都醒着，还在继续写 `_(:з」∠)_` 随后我们进行了联调，并且修改了第一版与数据库表相关的 UI，变成了更像表的结构，这个时候项目的主要功能都已经实现结束了，这个时候大概是早上 9 点。\n\n随后，我开始着手写 PPT 与 README，进行 demo 的录制。在中午的时候与女朋友玩了一局王者荣耀，结束后就到了答辩的时间。\n\n## 良好的答辩是成功的一半的一半的一半的一半的一半\n\n我们组是第十一个答辩的，所以前面听了几组，感觉很多组的 idea 都非常有趣。轮到自己上场的时候，着重强调了功能，演示了 demo，介绍了架构，吹了一下前景（等于没有）。内容而言自己感觉还可以，就是形象不是特别好，人比较憔悴，因为熬夜头发比较油所以戴着帽子显得不是很尊重，而且也有点驼背。\n\n在听过所有人的答辩后，我觉得大概是已经没戏了。有很多组的 idea 是真的非常棒，要技术有技术要场景有场景。但是可能做游戏天生就在展示上比较有优势，而且做的东西也确实比较有趣，最后误打误撞地拿到了二等奖。这可以说是非常有成就感了，要是放在之前，我会觉得一个 hackathon 的二等奖也就只能说说，但是这次的质量让我觉得有种成就达成的感觉，于是决定把它放在我的简历里 =。=\n\n在整场比赛里，给我留下的印象最深刻的项目是 [xcbuild](https://github.com/setekhid/ketos)，他们希望通过实现一个 `docker build` 的替代品，希望能优化 CI 场景下镜像的构建方式。当然还有很多其他有趣的项目，可以去 [Go Hack 17 主页](gohack2017.golangfoundation.org) 里去看看。\n\n这篇文章就到此为止了 :)\n\n## 许可协议\n\n- 本文遵守[创作共享CC BY-NC-SA 3.0协议](https://creativecommons.org/licenses/by-nc-sa/3.0/cn/)\n- 网络平台转载请联系 \u003cmarketing@dongyue.io\u003e\n","cover":"","link":"go_hack_17_参赛日记.html","preview":"\u003cp\u003e2017 年 10 月 21 日，由 Golang Foundation 和 PingCAP 联合举办的 Go Hack 17 在上海心动网络举行，东岳的小哥哥 @gaocegege 和 @codeworm96，以及工作一年的的 Go 工程师 @hawkingrei 一起组成了队伍 ，参加了这次 hackathon，凭借 killy: Play TiDB in Minecraft! 取得了二等奖以及 PingCAP 赞助的专项奖。这篇文章是 @gaocegege 第一人称视角的 hackathon 记录。\u003c/p\u003e\n","title":"Go Hack 17 参赛日记"},{"content":"\n\nKubernetes 是由 Google 捐赠给 [CNCF](https://www.cncf.io/) 的一个容器编排框架，也是目前应用最为广泛的编排框架之一。这篇文章是对 Kubernetes 1.8 中的 Scheduler（以下称为 kube-scheduler）的介绍，如果要阅读本文，需要对 Kubernetes 的基本概念如 pod, node 等有所了解。\n\n## 调度过程\n\n在读代码之前，先对 Kubernetes 整体的调度过程做一个简单的介绍。如果你对 Kubernetes 的调度过程已经熟悉的话，可略过不读。\n\nKubernetes 的调度的目的是把一个 pod 放在它最合适的 node 上去运行，所以调度的过程可以被理解为找一个 node，把 pod 放上去的过程。整个过程可以类比为喜闻乐见的相亲活动，pod 是相亲者，node 是所有可选的相亲对象，而 kube-scheduler 就像是相亲网站，它会负责根据相亲者的要求，找到与其要求最接近的相亲对象。当然这里也有一些不同点，比如每个 node 可以运行多个 pod，但是相亲者与相亲对象绑定以后应该是不能再跟别人进行喜闻乐见的相亲活动了/w\\\n\n出于性能，可扩展性以及其他各个方面的考虑，Kubernetes 的调度分为两个过程，第一个过程叫做 Predicates，第二个过程叫做 Priorities。\n\n在 Predicates 过程中，kube-scheduler 会先执行一系列被称为 predicate 的函数，过滤掉不符合硬性条件的 node。这个环节可以对应相亲活动中的硬条件过滤，比如你想找一个程序员，那相亲网站会帮你过滤掉所有不是程序员的选择。而所有通过了 Predicates 过程的 node，都会进入下一个过程。\n\n在 Priorities 过程中，kube-scheduler 会将所有通过 Predicates 过程的 node 根据自己的标准打分，然后从中选择一个得分最高的 node，将其与 pod 绑定在一起，即在该 node 上运行此 pod。这就好比，相亲网站过滤好了潜在的相亲对象，会再帮你对他们做一个打分，然后推荐给你一个条件最好的给你。（不要问我为什么这么熟练）\n\n\u003cfigure\u003e\n\t\u003cimg src=\"/images/posts/kubernetes/initial-state.png\" alt=\"State\" height=\"300\"\u003e\n\u003c/figure\u003e\n\n文字性的叙述过于单调，这里用图来说明这个过程。在图中一共有 16 台服务器，有着不同的配置。\n\n\u003cfigure\u003e\n\t\u003cimg src=\"/images/posts/kubernetes/algorithm.png\" alt=\"State\" width=\"500\"\u003e\n\u003c/figure\u003e\n\n经过了两个 predicate 后，过滤掉了不满足条件的 node，剩下的 node 都足以运行 pod，这时候就需要 Priorities 过程来找到最适合的那个 node。经过两轮 priority 后，发现了一个最适合的 node，于是 pod 和 node 终于在一起了。在绝大多数情况下，调度就结束了。\n\n这里特此说明，这些图只是为了说明调度的过程，Kubernetes 支持的 predicate 和 priority 的维度并不是 CPU 和 Memory。\n\n## 代码编译\n\n编译 kube-scheduler 只需要运行 \n\n```bash\nmake all WHAT=plugin/cmd/kube-scheduler\n```\n\n就可以了，编译后的结果会被放置在 `${KUBERNETES_PATH}/_output/bin/` 下。\n\n## 浅入理解\n\n接下来就进入了最激动人心的代码阅读部分。kube-scheduler 的入口是在 [`plugin/cmd/kube-scheduler/scheduler.go`](https://github.com/kubernetes/kubernetes/blob/release-1.8/plugin/cmd/kube-scheduler/scheduler.go) 中，因此如果要阅读调度的代码，从这里开始就可以了。\n\n不过 `main` 函数只是告诉你他是怎么启动的，真正的逻辑是从 [`plugin/cmd/kube-scheduler/app/server.go#L68`](https://github.com/kubernetes/kubernetes/blob/release-1.8/plugin/cmd/kube-scheduler/app/server.go#L68) 开始的。在 `Run` 函数中，首先创建了一个 Kuberntes Clientset，这可以理解为是 kube-scheduler 跟 Kubernetes 进行交互的 client，通过它可以拿到集群上 node，pod 等等的信息。然后根据这个 client 创建出对 node 和 pod 等等资源的 informer，这里用了一点点的 trick，来规避 import cycle。以 node informer 的逻辑为例，其创建的逻辑在 [`staging/src/k8s.io/client-go/informers/core/v1/node.go#L47`](https://github.com/kubernetes/kubernetes/blob/release-1.8/staging/src/k8s.io/client-go/informers/core/v1/node.go#L47)。Informer 有点像是观察者模式的样子，会 watch 一种资源的变化，这里水很深，代码挺复杂的，好奇的话建议仔细看看。在创建 kube-scheduler 的过程中，几乎所有的 informer（除了 pod informer），都是通过一个 factory 来做的，这样可以防止频繁地创建。之后就是 scheduler 去获取 leader 的地位，然后执行 [`plugin/pkg/scheduler/scheduler.go#L159`](https://github.com/kubernetes/kubernetes/blob/release-1.8/plugin/pkg/scheduler/scheduler.go#L159) 中的 run 函数，真真正正地开始提供相亲服务了。\n\n而实际上，这个 scheduler 也只是一层抽象，真正的 scheduler 的算法，是由 [`plugin/pkg/scheduler/core/generic_scheduler.go`](https://github.com/kubernetes/kubernetes/blob/release-1.8/plugin/pkg/scheduler/core/generic_scheduler.go) 提供的。如果你想替换原本的调度算法，可以从这个地方入手，也可以自己重新写一个全新的 scheduler，然后在 [`pkg/scheduler/factory/factory.go#L708`](https://github.com/kubernetes/kubernetes/blob/release-1.8/plugin/pkg/scheduler/factory/factory.go#L708) 直接修改创建的逻辑。\n\n在真正的逻辑中，一共有这么两个比较重要的函数：`Schedule`，`Preempt`。分别对应着调度和抢占调度的逻辑。\n\n先看 `Schedule` 函数，之前讲的 Predicates 和 Priorities 过程，就是在这个函数里进行的。在有了之前的积淀，这个函数其实很容易读懂。不过值得注意的是，在 Predicates 过程中，因为数据是没有依赖的，就是说检查每个节点是不是合格的节点其实是独立的事件，所以可以被并发来处理，在目前的实现中是会有 16 个独立的 worker 来处理所有的 Predicates 检查的。在 Priorities 过程中，数据不是完全独立的，因此完全并发的做法是行不通的，于是被实现成了 Map Reduce 的模式。可以不依赖其他的节点进行的计算，在 Map phase 来做，不能的就在 Reduce phase 来做。但是由于之前是完全单线程的实现，为了兼容性，目前在代码里可以看到单线程和并发的实现都存在在代码中。Map Reduce 模式的新实现是从 [`generic_scheduler.go#L404`](https://github.com/kubernetes/kubernetes/blob/release-1.8/plugin/pkg/scheduler/core/generic_scheduler.go#L404) 开始的，Map phase 的做法跟之前的 Predicates 是一样的，而 Reduce 是单线程来做的。\n\n值得注意的是，有一些 priority 函数不太适合用 Map Reduce 模式来进行处理，如果你感兴趣的话可以看看 [issues#51455](https://github.com/kubernetes/kubernetes/issues/51455)，这里有一些关于这些函数的讨论。\n\n再看看 `Preempt` 函数，这是一个比较新的 feature，支持 Pod 的抢占，具体的设计可以参见 [design proposal](https://github.com/kubernetes/community/blob/master/contributors/design-proposals/scheduling/pod-preemption.md)。大致的意思是说如果一个高优先级的 pod 没地方跑了，就杀掉一个在跑的低优先级的 pod，优先运行高优先级的 pod。在实现上，首先调度器会先去寻找那些可能运行这个 pod 的 node，如果 node 是因为一些诸如 selector 不 match 之类的问题被过滤掉了，那是无解的，但是如果是不是因为特别硬性的要求，而是因为资源不够运行这个 pod 之类的，那就列为潜在的合格 node。然后，调度器会在所有潜在的合格 node 上寻找可以被杀掉的 pod，如果不止一个 node 在杀死 pod 后可以满足要求，那就再经过一番选择，主要是选出优先级最低的 pod 所在的 node。选择的过程在 [`generic_scheduler.go#L501`](https://github.com/kubernetes/kubernetes/blob/release-1.8/plugin/pkg/scheduler/core/generic_scheduler.go#L501)，并不难懂。\n\n总体来说，我觉得读起来还是很简单的，本文就到此为止，系列下一篇应该是对 [Nomad](https://www.nomadproject.io/) 的介绍，大概应该就是在最近吧。\n\n## 许可协议\n\n- 本文遵守[创作共享CC BY-NC-SA 3.0协议](https://creativecommons.org/licenses/by-nc-sa/3.0/cn/)\n- 网络平台转载请联系 \u003cmarketing@dongyue.io\u003e\n","cover":"","link":"浅入了解容器编排框架调度器之_kubernetes.html","preview":"\u003cp\u003eKubernetes 是由 Google 捐赠给 CNCF 的一个容器编排框架，也是目前应用最为广泛的编排框架之一。这篇文章是对 Kubernetes 1.8 中的 Scheduler（以下称为 kube-scheduler）的介绍，如果要阅读本文，需要对 Kubernetes 的基本概念如 pod, node 等有所了解。\u003c/p\u003e\n","title":"浅入了解容器编排框架调度器之 Kubernetes"},{"content":"\n\n[Processing.R](https://github.com/gaocegege/Processing.R) 是我在 [Jeremy Douglass](http://jeremydouglass.com/) 指导下，为 [Processing](https://processing.org/) 实现的一个 R 语言模式，这是一个 [Google Summer of Code 2017](https://summerofcode.withgoogle.com/projects/) 项目。这篇文章会讲一讲它的应用，以及实现。\n\n至于这篇文章的受众，我也不是很清楚 ┑(￣Д ￣)┍ 爱看就看看吧 =。=\n\n## Processing 是什么\n\n这里有一篇文章：[Processing是干嘛的？艺术家学编程能做什么？](https://zhuanlan.zhihu.com/p/25432507)，我个人觉得介绍的很到位。我这里就再稍微说一下，我对 Processing 的看法。\n\nProcessing 从功能上而言，是一个做 creative coding 的编程语言，Processing 的 IDE 也直接被称作 Processing Development Environment（缩写 PDE）。\n\n从一个软件工程师的角度来讲，Processing 跟传统的编程语言最大的不同在于，一个完整的 Processing 程序（在 Processing 的语境中，完整的程序被称作 Sketch），一定会有一个图形化的输出。这个输出可以是 2D 图形，3D 图形，也可以是动画，等等。Processing 本身是用 Java 实现了一个编译器，其本身的语法也是跟 Java 几乎一致，因此可以把它当做 Java 的一个 DSL（对语言学不是很懂啦）。Processing 为了使得用户能够更好地进行图形化编程，实现了很多简练的函数，使得寥寥数行就可以实现一个非常简单的图形化应用。\n\n从一个艺术家的角度来讲，因为我不是一个艺术家，我也不知道怎么讲，所以就随便讲讲。绝大多数艺术家，在我看来，在写代码的能力上可能稍微有所欠缺（希望没有冒犯到你）。因此，Processing 对于他们而言，最吸引人的点应该是在于其简单易用。\n\n### 一个简单的例子\n\n这里以一个非常简单的例子介绍 Processing 可以做的事情。\n\n```\nvoid setup() {\n  size(640, 360);\n  background(102);\n}\n\nvoid draw() {\n  // Call the variableEllipse() method and send it the\n  // parameters for the current mouse position\n  // and the previous mouse position\n  variableEllipse(mouseX, mouseY, pmouseX, pmouseY);\n}\n\n\n// The simple method variableEllipse() was created specifically \n// for this program. It calculates the speed of the mouse\n// and draws a small ellipse if the mouse is moving slowly\n// and draws a large ellipse if the mouse is moving quickly \n\nvoid variableEllipse(int x, int y, int px, int py) {\n  float speed = abs(x-px) + abs(y-py);\n  stroke(speed);\n  ellipse(x, y, speed, speed);\n}\n```\n\n先讲效果，这段代码会根据鼠标的位置和鼠标移动的速度在画布上不停的画圆。\n\n在代码中可以看到三个函数，其中 `setup` 和 `draw` 是内置函数，就像是传统编程语言中的 main 函数一样，是整个程序的入口。`setup` 会进行一些设定，比如画布的大小，以及背景颜色。而每当需要绘制新的一帧时，Processing 就会调用 `draw` 函数。因此如果 `draw` 函数每次调用结果都一样，那就是一个静态的图形，如果是不一样的，得到的就是动态的效果。`variableEllipse` 是负责绘制圆形的函数。其参数是鼠标的当前坐标和上一帧的坐标，它会根据坐标计算速度，随后去绘制圆形。如果你感兴趣的话，可以去 [Examples - Pattern](https://processing.org/examples/pattern.html) 亲自试试效果 :)\n\n## Processing.R 是什么\n\n之前提到 Processing 是基于 Java 的 DSL，而且是运行在 JVM 上的。而诸如 Python, Ruby, R 等等语言，也都有在 JVM 上的实现，因此 Processing 也可以通过切换模式的方式来使用其他语言来写 Sketch 的逻辑。\n\n而 [Processing.R](https://github.com/gaocegege/Processing.R)，就是利用 [renjin](http://www.renjin.org/) 实现的 Processing 在 R 语言上的支持。\n\n\u003cfigure\u003e\n\t\u003cimg src=\"https://github.com/gaocegege/Processing.R/raw/master/raw-docs/img/editor.png\" alt=\"Processing.R\" width=\"500\"\u003e\n\u003c/figure\u003e\n\n\u003cfigure\u003e\n\t\u003cimg src=\"https://github.com/gaocegege/Processing.R/raw/master/raw-docs/img/demo.gif\" alt=\"Processing.R Demo\" width=\"200\"\u003e\n\u003c/figure\u003e\n\nProcessing 在 R 语言上的实现，依赖了一个 JVM 上的 R 解释器，每当 Processing 需要调用 draw 等等函数时，都会转而执行 R 代码中相对的定义。目前，Processing.R 支持了绝大多数 Processing 的语法，与此同时支持 Processing 自身众多的库以及 R 语言的包（两者只测试了部分）。这使得 Processing.R 能够在拥有便捷的图形化能力的同时，使用 R 语言中各种方便的包。\n\n## 下载与安装\n\nProcessing 本身下载和安装都特别简单，而且是多平台的，在[此处](https://processing.org/download/)即可找到适合你的版本。而在 Processing 的 Contribution Manager 中的 Modes 一栏中，可以下载 Processing.R。随后在主界面右上角的下拉框中选择 R 即可。\n\n\u003cfigure\u003e\n\t\u003cimg src=\"https://user-images.githubusercontent.com/5100735/29493417-df2b614e-85c7-11e7-98c5-d9f20cf780a4.PNG\" alt=\"下载与使用\" width=\"500\"\u003e\n\u003c/figure\u003e\n\n目前 Processing.R 仍然会积极地进行维护，如果你感兴趣，可以与我联系，还有很多坑等着呢，而且也可以以这个项目为蓝本，拿去申请下一年的 Google Summer of Code，总而言之欢迎各种形式的贡献。原本想做个标题党，发现自己没有 UC 小编的能力，只好找了这么一个不明所以的标题，谢谢你还不辞辛劳地点进来看看 :)\n\n## 许可协议\n\n- 本文遵守[创作共享CC BY-NC-SA 3.0协议](https://creativecommons.org/licenses/by-nc-sa/3.0/cn/)\n- 网络平台转载请联系 \u003cmarketing@dongyue.io\u003e\n","cover":"","link":"安利时间:_processing_+_r.html","preview":"\u003cp\u003eProcessing.R 是我在 Jeremy Douglass 指导下，为 Processing 实现的一个 R 语言模式，这是一个 Google Summer of Code 2017 项目。这篇文章会讲一讲它的应用，以及实现。\u003c/p\u003e\n","title":"安利时间: Processing + R = ?"},{"content":"\n\n[Unikernels: Beyond Containers to the Next Generation of Cloud](http://www.oreilly.com/webops-perf/free/unikernels.csp) 是 [Russ Pavlicek](https://www.linkedin.com/in/rcpavlicek/) 的一本动物书（虽然是 O'Reilly 的，但是封面不是动物，是石榴），这本书对 Unikernel 有着比较全面的介绍，而且电子书是免费的，值得一读。\n\n## 啥是 Unikernel？\n\n从 2014 年以来，容器以一种不可逆转的态势席卷了全球，Unikernel 是很多人眼中的下一个容器。如果要了解什么是 Unikernel，首先需要了解什么是 kernel，kernel 是操作系统中的一个概念。应用要运行起来，是肯定要跟硬件打交道的，但是如果让应用都直接操作硬件，那一定是一场灾难。那内核就是在应用与硬件中间的一层抽象，内核提供了对底层硬件的抽象，比如把硬盘抽象成了文件，通过文件系统进行管理。传统的内核会将所有的硬件抽象都实现在其中，其中的代表就是 Linux，这样的内核被称为宏内核（Monolithic Kernel)。在宏内核中，所有的模块，诸如进程管理，内存管理，文件系统等等都是实现在内核中的。这样虽然不存在通信问题，但是任何一个模块的 bug 会使得整个内核崩溃。\n\n于是学者们提出了微内核（Micro Kernel）的概念，在内核中只保留必要的模块，比如IPC，内存管理，CPU调度等等。而其他，诸如文件系统，网络IO等等，都放在用户态来实现。这样会使得内核不那么容易崩溃，而且内核需要的内存小了。但是由于模块间的通信需要以 IPC 的方式进行，因此有一定的 overhead，效率不如很莽的宏内核。\n\n那后来又有了混合内核（Hybrid Kernel)，把一部分不常使用的内核模块，或者是原本需要的时间就很长，因此 IPC 的 overhead 看起来就不是那么夸张的功能，移出内核，而其他的就会放在内核里。\n\n再后来还有 Exokernel，但是太长了就不讲了，这部分内容在 [CSP 课堂笔记之 UniKernel](http://gaocegege.com/Blog/csp/unikernel) 一文中有更详细的解释。\n\n直接说 Unikernel，[Unikernel 的官方解释](http://unikernel.org/)是\n\n\u003eUnikernels are specialised, single-address-space machine images constructed by using library operating systems.\n\n翻译一下就是\n\n\u003eUnikernel 是专用的，单地址空间的，使用 library OS 构建出来的镜像\n\n其最大的卖点就是在，没有用户空间与内核空间之分，只有一个连续的地址空间。这样使得 Unikernel 中只能运行一个应用，而且对于运行的应用而言，没有硬件抽象可言，所有的逻辑，包括应用逻辑和操作硬件的逻辑，都在一个地址空间中。\n\n## 这样有啥好？\n\n哦，原来 Unikernel 就是一个单一内存空间的内核镜像，其中只能有一个应用在运行，那这样有啥好呢，为啥值得我放弃 Linux 而用你这么一个看上去像是阉割版的内核呢？好处就在，小，快，安♂全 /w\\\n\nUnikernel 镜像都很小，由 [MirageOS](https://mirage.io/) 实现的一个 DNS server 才 184KB，实现的一个 web server 674 KB，小到恐怖的程度。\n\n然后就是快，启动很快。因为镜像都很小，所以起停都在毫秒级别，比传统的 kernel 要快多了。\n\n最后是安全，一般来讲，小的东西相对而言比较安全。Unikernel 中没有 Shell 可用，没有密码文件，没有多余的设备驱动，这使得 Unikernel 更加安全。\n\n## 开发测试与传统有啥不同？\n\nUnikernel 在真正实践中，如何开发与测试是一个值得关注的问题。在开发过程中，开发者可以假定自己在传统的操作系统上进行开发，而所有内核相关的功能，暂且由开发机的操作系统提供。\n\n而在测试环境中，大部分 Unikernel 的实现会将应用代码与需要的内核模块构建成 Unikernel 后，再将其跑在一个传统的操作系统上，利用传统操作系统上的工具来测试 Unikernel。以 [Rumprun](https://github.com/rumpkernel/rumprun) 为例，它可以通过 KVM/QEMU 来运行一个 Rumprun Unikernel VM，随后用 Host OS 上的 GDB 来对其进行调试，具体细节可见[此处](https://github.com/rumpkernel/wiki/wiki/Howto:-Debugging-Rumprun-with-gdb)。关于调试就介绍到此，如果你想了解更多，[Hacker News 上的这个 post](https://news.ycombinator.com/item?id=10954132) 可能会给你一些启发。\n\n在发布阶段，这是 Unikernel 最简单的事情了。Unikernel 最后的产物就是一个 kernel image，可以在 Hypervisor，Bare Metal 等等各种环境上运行。\n\n所以可以看到，其中 Unikernel 在软件过程中与传统方式最大的不同就在于调试与测试。而在发布的阶段，传统的方式可能发布的是一个应用，时髦一点那一个容器镜像，而 Unikernel 则是一个高度定制化的 kernel。\n\n## 目前的 Unikernel 项目\n\n介绍完 Unikernel，接下来将介绍下目前比较成气候的 Unikernel 项目，Unikernel 的实现大部分都是语言特定的。因为涉及到具体语言的运行时，所以很难有一个项目可以适配所有的技术栈。\n\n[MirageOS](https://mirage.io) 应该是名气最大的一个 Unikernel 项目，它是使用 OCaml 进行开发的，也是要求开发者懂 OCaml 才行。与其他 Unikernel 相比，它非常成熟，而且有一些[论文](https://mirage.io/wiki/papers)，对钟爱论文的同学非常友好。\n\n[HaLVM](https://github.com/GaloisInc/HaLVM#readme) 也是一个比较早的 Unikernel 项目，它可以帮助 Haskell 程序员们把自己的 Haskell 程序构建成 Unikernel。如果你不会 Haskell，那就算了 =。=\n\n[ClickOS](http://cnp.neclab.eu/clickos) 是一个比较独特的项目，他也非常古老了，但是原本 Click 并不是以 ClickOS 的形式出现的，原本它只是一个支持定制的 router，后来就变成了 ClickOS，一个基于 Unikernel 的 router。它也有很多[论文](http://www.read.cs.ucla.edu/click/publications)，大部分都是关于 Click 本身，而不是 Unikernel 实现的。\n\n[Rumprun](https://github.com/rumpkernel/rumprun/) 也是一个非常独特的项目，其利用了 [Rump Kernel](http://rumpkernel.org/)，理论上 POSIX 兼容的程序，都可以用 Rumprun 来构建成 Unikernel。\n\n如果这些还不能满足你的好奇心，[Open source work on unikernels](http://unikernel.org/projects/) 上列出了众多的 Unikernel 项目，如有需要还请自行浏览。\n\n## Unikernel, Docker，Hyper 与 Linuxkit\n\n对 Unikernel 的介绍就是这些了，最后再谈谈自己对目前很火的一些概念的看法，以及它们之间的联系。\n\nUnikernel，在我看来，是另一种形式上的容器。在一个 Unikernel 中，只能运行一个应用，这与容器的哲学不谋而合。但现在容器最吸引人的特性并不是它的便捷，而是在它的分发。Docker 让我们看到了，原来应用的分发可以这么无痛。而 Unikernel 与容器相比，虽然可以做的更小更安全，而且也不需要有 Docker Daemon 这样的后台程序存在，甚至不需要 Host OS，或者 Hypervisor，但是它一是与传统的软件过程有较大的出入，二是在分发等等方面不能做到像容器那样方便。所以它目前肯定不会成为主流的应用分发方式，还需要进一步探索。\n\n为了能够让 Unikernel 尽快进入生产环境，有一项工作很值得关注。\n\n![](/images/posts/unikernel/unikernel.png)\n\n在 Unikernel 里运行一个 Docker Container，想法很美好，但是同样也有很多问题。这样其实并没有利用到容器便于分发的优势，也没有完全发挥 Unikernel 的优势，我觉得这不是未来。不过作为一种折中方案值得一看，可惜从 DockerCon 15 之后就没听见什么动静了。\n\nHyper Container 的技术特别独特，之前在 [Docker 与 Hyper](http://gaocegege.com/Blog/docker-rambles) 一文中介绍过，这里不再多说。他们的实现很完整，有对标 runc 的 runv，有扩展 Kubernetes 中 container runtime 的 frakti，虽然我没有尝试过，但是我觉得是比 Docker in Unikernel 更加可行的方案，讲道理很有前途。\n\nLinuxkit 是 Docker 改名 Moby 后随之发布的一个项目。Linuxkit 严格来说是一个构建操作系统的工具集，可以用来构建 Unikernel，但是也可以用来构建最小化的 Linux Kernel，目前还不知道要往什么方向发展。\n\n这些概念或多或少都有相互重叠的部分，也没有谁一定胜过谁的说法，但都有一个特点：有趣。它们都有自己不同的应用场景，本来嘛，Docker 也不是银弹。\n\nPS：本文都是纸上谈兵，作者本人并无对 Unikernel 在生产环境中的使用经验（应该暂时也没有人有），大家看看就好，如有疏漏还请不吝指教:)\n\n## 许可协议\n\n- 本文遵守[创作共享CC BY-NC-SA 3.0协议](https://creativecommons.org/licenses/by-nc-sa/3.0/cn/)\n- 网络平台转载请联系 \u003cmarketing@dongyue.io\u003e\n","cover":"","link":"unikernel:_从不入门到入门.html","preview":"\u003cp\u003eUnikernels: Beyond Containers to the Next Generation of Cloud 是 Russ Pavlicek 的一本动物书（虽然是 O\u0026rsquo;Reilly 的，但是封面不是动物，是石榴），这本书对 Unikernel 有着比较全面的介绍，而且电子书是免费的，值得一读。\u003c/p\u003e\n","title":"Unikernel: 从不入门到入门"},{"content":"\n\n本文的受众主要是想在暑假找点事情做，挣点外快的同学，亦或是想积累一下参与真实软件开发经验的同学。\n\n## 背景介绍\n\n[Google Summer of Code](https://developers.google.com/open-source/gsoc/)（下称作 GSoC）是谷歌组织并提供经费，面对全球（绝大多数国家）在读学生的在线编程项目。它的[官方介绍](http://write.flossmanuals.net/gsocstudentguide/what-is-google-summer-of-code/)是：\n\n\u003e Google Summer of Code (GSoC) is a global program that matches students up with open source, free software and technology-related organizations to write code and get paid to do it! The organizations provide mentors who act as guides through the entire process, from learning about the community to contributing code. The idea is to get students involved in and familiar with the open source community and help them to put their summer break to good use.\n\n即是：\n\n\u003e Google 编程之夏是一个全球性项目，旨在为学生们和开源、自由软件、技术相关的组织建立联系，让学生们贡献代码并获得报酬！组织会提供导师，在学生从熟悉社区到贡献代码的整个过程中提供指导。这个想法的目的是让学生们参与和熟悉开源社区，并帮助他们充分利用暑假时间去得到锻炼。\n\n整个活动的流程是这样的：在每年的二月末，GSoC 会公布一个 Mentoring organizations 的列表，比如 [2017 Organizations](https://summerofcode.withgoogle.com/organizations/)，这个列表是受到谷歌认可的开源社区或者组织。随后学生可以从列表中挑选出适合自己的 organization，并且在 organization 的 ideas list 中找出自己感兴趣，觉得可以胜任的 idea，提出申请。一个学生最多可以申请 5 个 idea，申请在 3 月末开始，4 月初结束。在 5 月份，Google 会公布所有入选的学生，社区会给每个学生分配一个或多个 mentor，mentor 负责指导学生的工作，并评估学生的工作是否满足了社区的要求。\n\n公布之后，会有持续一个月的 Community Bonding Period，在这个阶段学生需要尽快融入社区，跟自己的 mentor 建立联系，熟悉社区工具链，交流工具等等。6 月份开始正式的开发工作。开发工作一共有三个阶段，同时也会有三个 evaluation。每个阶段大约一个月，会有一个小目标，如果 mentor 认为你完成了阶段性的目标，Google 会在每次 evaluation 结束后发放奖金。三次一共的奖金在 1200 - 6600 美刀之间。具体的数额跟所在地的 [Purchasing Power Parity](https://developers.google.com/open-source/gsoc/help/student-stipends) 有关,中国是 3600 美刀。\n\n整个项目大概在 9 月份结束，但是社区的期望肯定是学生能够继续进行贡献，这也是他们获得新的 contributors 的一个重要途径。并且在持续贡献后，学生可以在来年的 GSoC 时申请成为 mentor，虽然 mentor 没有奖金，但是有一个 Google 组织的 Mentor Summit，据说就是公费旅游。\n\n## 名词解释\n\n因为在申请的时候不同的社区对于同一个对象的叫法都有所不同，所以这里列一些常见的名词的解释。\n\n| 名词        | 解释           |\n| ------------- |-------------|\n| Organization，组织，社区    | Google 公布的 Mentoring organizations 中的组织，可以接收学生参与 GSoC |\n| 学生，申请者    | 申请参加 Google Summer of Code 的学生 |\n| Slots         | 社区可以接收的学生数量，由 Google 决定 |\n| Mentor，导师   | 学生申请成功后社区指定的导师，指导学生的具体工作，以及负责评估完成度  |\n| Stipend，奖金，奖励   | 在学生完成阶段性目标后由 Google 发放的奖金，具体的数额跟所在地的 [Purchasing Power Parity](https://developers.google.com/open-source/gsoc/help/student-stipends) 有关  |\n| Evaluation    | 阶段性检查，mentor 会检查学生有没有达成阶段性成果，影响奖金发放 |\n\n## 申请之前的准备\n\n申请是一个比较漫长的过程，如果想更加稳妥一点，建议不要在谷歌公布 Mentoring organizations 列表后再进行准备，而是要提前选定一个或几个社区，进行持续的贡献和交流，尽可能混一个脸熟。这样与后期才开始准备申请的同学而言就有了很大的优势。除此之外，要日常性地多给开源项目做贡献。在申请的时候很多社区会要求学生提供其开源贡献的经历，无论是不是对自己社区的。这时如果你已经是其他社区的积极贡献者了，那无疑是会加分的。\n\n对于社区的选择，如果你偏向保守，可以多回顾往年的列表，有一些组织是雷打不动的，比如 Python Software Foundation, Apache 这些老牌开源社区，这些相对于其他组织，有更大的可能被谷歌选中。如果你喜欢高风险，可以事先问问社区是否有申请 GSoC organization 的打算，如果有，而且你也看好，可以选择这样的社区进行贡献。\n\n至于贡献的时间，窃以为比较理想的时间是前一年的 12 月份或者同年的 1 月份开始，就要尝试着去给社区做一些微小的工作。这些工作包括但不限于：\n\n* 贡献代码，无论什么社区，都喜欢高质量的 PR\n* Review PR，给别人的 Review 点赞\n* 提交 Bug\n* 添补更新文档\n* 在 IRC 里解决别人的问题\n\n在贡献的过程中，要注意交流，不要只是提交了就走人了，最好是可以时刻跟进，及时回复别人的信息也是一种表明你的热情的方式。\n\n## 申请\n\n### Organization 介绍\n\n申请真正开始于谷歌公布的 Mentoring organizations 列表，这里大致介绍下其内容。\n\n![](/images/posts/gsoc/processing-org.png)\n\n以 2017 年 GSoC 其中的一个开源组织 [The Processing Foundation](https://summerofcode.withgoogle.com/organizations/4962961559912448/) 为例，介绍一下 GSoC 主页上 organization 的页面布局。每个 organization 都会有一段介绍性的文字，这个不是很关键。右边的一栏是比较重要的，其中 Technologies 是方便大家在搜索 organization 的。上面的 VIEW IDEAS LIST 比较重要，一般来说每个社区会事先提出一些他们期望的 idea，学生可以就这些 idea 进行申请。当然社区也鼓励学生提出自己的 idea。其下的 Chat 和 Email 一般来说会写明该社区常用的交流工具，在申请的过程中往往需要频繁地与社区相关人员交流。\n\n### 正式申请\n\nProposal，是一个申请时很关键的材料。它是学生在申请时需要提交的一个设计文件，在其中，学生往往需要写明自己的背景（学术背景，开源贡献经历等），对 idea 的了解与认识，以及大致的实现思路和方法。Proposal 的书写是没有定式的，只要可以突出你的长处就好，这是社区对你了解的唯一途径，所以需要你把自己所有的优势都要写在其中。\n\n[Proposal for Processing.R](https://docs.google.com/document/d/1b0HhRVKtCJkDaxP9dfSwzthzX0FRv6Y_0Yk58r634TA/edit?usp=sharing) 是我在申请时的一份 Proposal，可以列为参考，介绍下常规的写法。\n\n首先是 Project Description，这个部分就是让社区知道你对 idea 没有理解错，你深刻地了解这个 idea 想做的是什么。三言两语就好了。\n\n然后是 Implementation，我个人觉得是比较重要的部分。要向社区证明你已经有了完整的实现思路，现在差的就是写代码实现而已了。\n\n其次，是 Development Process，社区肯定更喜欢那些风险低，feature 吸引人的申请。一个好的 schedule 可以让社区相信你是真的已经做好了准备。精确到天自然最好，但是基本来说比较难，周和月都是不错的选择。不过有一点需要注意，不要把所有时间都安排的满满的，还是需要有一些 buffer 的。不然看起来太假了 =。=\n\n最后是 About Me，因为我对于申请的项目而言，没有什么积累，而且没有相关领域的贡献，所以把这一项放在了最后。如果你是申请 Kubernetes，而日常是 Docker 的 contributor，那把 About Me 放在最前面是更好的选择，完全看申请而定。\n\n一般来说这些是都要有的，还有一些其他的，社区特定的要求，这个也是要注意的。这里还有一些我认为写的比较好的 proposal：\n\n* [Integrate Unikernel Runtime](https://docs.google.com/document/d/1Vld4j0B-wk1A1827gIc5fzWHJlzQVqcYQnCAKJwe_ZM/edit?usp=sharing)\n* [Optimization of Distance Between Methods in Single Java Class](https://docs.google.com/document/d/1lWXpWhUN6cE06sjQANjWxamc_X3ddbSphTRSofChLyk/edit?usp=sharing)\n\n感兴趣也可以看下。\n\n### Community Bonding Period\n\n走到这一步，离拿钱就不远了，因为 GSoC 申请比完成更难。在 Community Bonding Period，你需要跟自己的 mentor 建立联系，积极融入社区等等，但是没有量化的标准，这个就不再多说了。\n\n### 开始写码\n\n写码这个，不同的项目有不同的要求。有一部分项目是给开源的 repo 贡献代码，因此要走整个 review 的流程，这想必大家都比较熟悉，不再多说。但是还有一部分项目，是 standalone 的，就是自己开了个 repo，自己写，比如我申请到的 [Processing.R](https://github.com/gaocegege/Processing.R)。这就会有很多问题，这里也着重说一下对于这一类项目的建议。\n\n首先，要明确之前 proposal 里写的 schedule 只是为了给社区信心的，事实上在开始写码之前，mentor 会跟你重新制定计划。所以如果你在 Community Bonding Period 写了很多 feature，很可能没有用，因为 mentor 说不定会给你重新制定要求。\n\n关于 standalone 的项目，跟 mentor 以及社区其他成员的交流是很关键的。因为你的 repo 别人都是没有 watch 的，所有的变动，可能只有你和你的 mentor 知道。如何让社区里的其他人看到你的贡献，非常重要。所以尽可能多在 IRC 里跟大家分享你遇到的问题，或者你的项目中的新 feature，可能会让你感觉到自己不是玩单机游戏。\n\n其次就是要尽早引入 CI，并且所有变动都以 PR merge 的方式进行，以保证代码质量。一个人的项目，质量很容易滑坡，CI 和 PR 可以让 mentor 对你的代码有一个很好的 review 体验，他也会更加积极一点。\n\n最后是不要太肝。因为自己的项目，每个 PR 的生命周期都是由自己负责的，很容易就会进入疯狂开发的状态，但是记住上面说的，在开始写码之前，mentor 会跟你重新制定计划 :)\n\n### Evaluation 与奖金发放\n\nEvaluation 是一个双向的评估，mentor 会评估学生的工作完成度如何，学生会评估社区和 mentor 对自己的帮助是否到位，学生对社区的评估可能会影响社区明年能够参加 GSoC 以及 slots 的数量，mentor 的评估决定学生能否拿到奖金。\n\n如果通过了 evaluation，奖金会在几天内到账。\n\n## 注意事项与 Tips\n\n1. **只有**学生才可以申请 GSoC。\n1. 一般来说 GSoC 主页需要科学上网才能访问。\n1. 时差问题是申请的时候需要注意的问题，这个需要格外注意，每年都有人错过申请。\n1. 奖金的发放是通过 [Payoneer](https://www.payoneer.com/home/) 发放的，如果是非美元账户，需要支付 4% 左右的换汇费用。\n1. 第一次入选 Mentoring organizations 的组织原则上只有 1 个或者 2 个 slots。\n\n## 结语\n\n这是一篇摸鱼作，希望能够对各位有所帮助。其实大家在选择开源社区的时候可以多问问有经验的人，尽可能选择一个友好的社区作为开始，这样会在开源的路上走的远一点。。\n\n## 相关文章\n\n* [Google 编程之夏(GSoC)：海量优质项目，丰厚报酬，你竟然还不知道？](https://zhuanlan.zhihu.com/p/27330699)\n\n## 许可协议\n\n- 本文遵守[创作共享CC BY-NC-SA 3.0协议](https://creativecommons.org/licenses/by-nc-sa/3.0/cn/)\n- 网络平台转载请联系 \u003cmarketing@dongyue.io\u003e\n","cover":"","link":"google_summer_of_code_申请指南.html","preview":"\u003cp\u003e本文的受众主要是想在暑假找点事情做，挣点外快的同学，亦或是想积累一下参与真实软件开发经验的同学。\u003c/p\u003e\n","title":"Google Summer of Code 申请指南"},{"content":"\n\n这篇文章是写给[东岳网络工作室](https://github.com/dyweb)的小伙伴们的 (广告:欢迎在交大的同学加入)，适用于有一定数据库背景并且想要了解时间序列数据库的同学。\nPS: 中文版是在[英文版](/introduction_to_time_series_database.html)之后写的，很生硬，请见谅。\n\n目录\n\n- 什么是时间序列数据库 (TSDB)\n- 时间序列数据库数据模型\n- 时间序列数据库演变\n- 时间序列数据库类型\n  - KairosDB\n  - InfluxDB\n- 热点话题\n  - 低延迟\n  - 数据\n  - 元数据索引\n  - Tracing\n\n## 什么是时间序列数据库 (TSDB)\n\n时间序列数据库 `Time Series Database` (TSDB) 相对于关系型数据库 (RDBMS)，NoSQL，NewSQL 还很年轻。\n但是，随着系统监控以及物联网的发展，已经开始受到更多的关注。\n维基百科上对于时间序列的定义是‘一系列数据点按照时间顺序排列’，\n但是我个人的理解是**存储在服务端的客户端历史**。\n时间序列数据就是历史，它具有**不变性**, **唯一性**以及**可排序性**。\n比如`在2017年9月3日21点24分44秒，华东区的机器001的CPU使用率是10.02%`，\n这个值不会像银行存款一样随着时间发生变化，它一旦产生了就不会有更新。\n下一秒的使用率是一个新的数据点，其他机器的使用率在其他时间序列里。\n并且**数据到达服务器的顺序并不影响正确性**，根据数据本身可以直接进行排序和去重。\n客户端发送本地的历史到服务器端，即使服务器端挂掉了，客户端依旧继续他本来要做的事情而不受到影响。\n对于很多客户端来说，发送数据到 TSDB 跟它的本职工作并没有关联。\n比如一个静态文件服务器的主要职责是传送文件而不是上报 HTTP 状态码。\n关系型数据库则起着完全不一样的作用，它是客户端做决定的主要依据，\n这就导致时间序列数据库和关系型数据库的读写规律有很大的不同。\n比如你取钱之前，银行的程序必须从数据库里找到你的那条存款记录，读出你的余额，确认不会透支才能把钱给你，\n然后更新你的余额。\n然而大多数时间序列数据库的客户端是只读(监控系统)或者只写(被监控的系统)，\n并且读取数据是并不是读取特定的某条，而是读取某个时间区间内的大量数据，比如`最近1小时的CPU使用率`远比\n`2017年9月3日21点24分44秒的CPU使用率`有用，脱离上下文的时间序列数据并没有什么作用。\n\n时间序列数据跟关系型数据库有太多不同，但是很多公司并不想放弃关系型数据库。\n于是就产生了一些特殊的用法，比如用 [MySQL 的 VividCortex](https://www.vividcortex.com/blog/2014/12/16/in-case-you-missed-it-building-a-time-series-database-in-mysql/),\n用 [Postgres 的 Timescale](http://www.timescale.com/)。\n很多人觉得特殊的问题需要特殊的解决方法，于是很多时间序列数据库从头写起，不依赖任何现有的数据库,\n比如 [Graphite](https://graphiteapp.org/)，[InfluxDB](https://github.com/influxdata/influxdb)。\n\n## 时间序列数据库演变\n\n时间序列数据库有[很多](https://xephonhq.github.io/awesome-time-series-database/?language=All\u0026backend=All)，\n下面列出的是一些我个人认为具有里程碑意义的数据库。\n很多数据库主页上并没有最初版本的发布日期，因此以 GitHub 上最早的 tag 作为发布日期。\n\n- 1999/07/16 [RRDTool First release](https://en.wikipedia.org/wiki/RRDtool)\n- 2009/12/30 [Graphite 0.9.5](https://github.com/graphite-project/graphite-web/releases/tag/0.9.5)\n- 2011/12/23 [OpenTSDB 1.0.0](https://github.com/OpenTSDB/opentsdb/releases/tag/v1.0.0)\n- 2013/05/24 [KairosDB 1.0.0-beta](https://github.com/kairosdb/kairosdb/releases/tag/v1.0.0-beta2a)\n- 2013/10/24 [InfluxDB 0.0.1](https://github.com/influxdata/influxdb/releases/tag/v0.0.1)\n- 2014/08/25 [Heroic 0.3.0](https://github.com/spotify/heroic/releases/tag/0.3.0)\n- 2017/03/27 [TimescaleDB 0.0.1-beta](https://github.com/timescale/timescaledb/releases/tag/0.0.1-beta)\n\n[RRDTool](https://oss.oetiker.ch/rrdtool/) 是最早的时间序列数据库，它自带画图功能，现在大部分时间序列数据库都使用[Grafana](https://github.com/grafana/grafana)来画图。\n[Graphite](https://graphiteapp.org/) 是用 Python 写的 RRD 数据库，它的存储引擎 [Whisper](https://github.com/graphite-project/whisper) 也是 Python 写的，\n它画图和聚合能力都强了很多，但是很难水平扩展。\n来自雅虎的 [OpenTSDB](http://opentsdb.net/) 使用 HBase 解决了水平扩展的问题。\n[KairosDB](https://kairosdb.github.io/) 最初是基于OpenTSDB修改的，但是作者认为兼容HBase导致他们不能使用很多 Cassandra 独有的特性，\n于是就抛弃了HBase仅支持Cassandra。\n有趣的是，在[新发布的](http://opentsdb.net/docs/build/html/new.html) OpenTSDB 中也加入了对 Cassandra 的支持。\n故事还没完，Spotify 的人本来想使用 KairosDB，但是觉得[项目发展方向不对以及性能太差]((https://labs.spotify.com/2015/11/16/monitoring-at-spotify-the-story-so-far/))，就自己撸了一个 [Heroic](https://github.com/spotify/heroic)。\n[InfluxDB](https://github.com/influxdata/influxdb) 早期是完全开源的，后来为了维持公司运营，闭源了集群版本。\n在 Percona Live 上他们做了一个[开源数据库商业模型正面临危机](https://www.youtube.com/watch?v=Kvf5jWZjw0U)的演讲，里面调侃红帽的段子很不错。\n并且今年的 Percona Live 还有专门的[时间序列数据库单元](https://www.percona.com/live/17/program/schedule/time-series)。\n\n## 时间序列数据库数据模型\n\n时间序列数据可以分成两部分，**序列**和**数据点**。\n序列就是标识符，比如`华东区机器001的CPU使用率`。\n数据点是时间戳和数值构成的数组。\n\n对于序列，主要的目的是方便使用者进行搜索和筛选。\n比如你需要查询`华东区所有机器的CPU使用率`。\n序列 `华东区机器001的CPU使用率` 的标识符是 `name=cpu.usage machine=001 region=cn-east`，\n查询则是 `name=cpu.usage machine=* region=cn-east`。\n为了处理大量的序列，需要建立（倒排）索引来提高查询速度。\n一些时间序列数据库选择使用外部搜索引擎来解决这个问题，比如 [Heroic](https://github.com/spotify/heroic) 使用了 Elasticsearch,\n另一些则选择自己写索引，比如 [InfluxDB](https://github.com/influxdata/influxdb), [Prometheus](https://prometheus.io/)。\n\n对于数据点，有两种模型，一个数组的点  `[{t: 2017-09-03-21:24:44, v: 0.1002}, {t: 2017-09-03-21:24:45, v: 0.1012}]`\n或者两个数组，一个存时间戳，一个存数值。前者是行存，后者是列存（不是列簇）。\n大部分基于现有数据库( [Cassandra](https://xephonhq.github.io/awesome-time-series-database/?language=All\u0026backend=Cassandra), [HBase](https://xephonhq.github.io/awesome-time-series-database/?language=All\u0026backend=HBase) ) 的是第一种。\n对于新的时间序列数据库第二种更为普遍，TSDB 属于 OLAP 的一个子集，列存能有更好的压缩率和查询性能。\n\n## 时间序列数据库类型\n\n时间序列数据库可以分成两类，基于现有的数据库或者专门为时间序列数据写的数据库。\n我们以 [KairosDB](https://kairosdb.github.io/) 和 [InfluxDB](https://github.com/influxdata/influxdb) 为例来分析。\n有很多时间序列数据库是[基于 Cassandra](https://xephonhq.github.io/awesome-time-series-database/?language=All\u0026backend=Cassandra) 的，\n[KairosDB](https://kairosdb.github.io/) 是其中比较早的一个。\n[InfluxDB](https://github.com/influxdata/influxdb) 是专用于时间序列的数据库，他们尝试了很多存储引擎，最后写了自己的 `Time Structured Merge Tree`.\n\n### KairosDB\n\n在看 KairosDB 之前我们先用一个简化版本的预热一下。\n[Xephon-K](https://github.com/xephonhq/xephon-k) 是我写的一个有多种存储后端的时间序列数据库(专门用来对付各种课程大作业)。\n它有一个非常 naive 的基于 Cassandra 的实现。\n\n如果你对 Cassandra 不熟的话，这里有个简单的介绍。\nCassandra 是一个列簇数据库，是谷歌 BigTable 的开源实现。列簇又被称作宽列。\n实质上是一个多层嵌套的哈希表。它是一个行存储，不是列存储。\n一些 Cassandra 的名词可以跟关系型数据库中的对应起来。\nCassandra 中的 `Keyspace` 就是指的 `database`, 比如一个博客和一个网店虽然使用同一个 MySQL 服务器，但是各用一个数据库以进行隔离。\nCassandra 中的 `Table` 是一个哈希表，他的 `Partition Key` 是哈希表的键(也被叫做物理行键)，它的值也是一个哈希表，这个哈希表的键是 `Cluster Key`，\n它的值还是一个蛤希表。\n当使用 CQL 创建一个 `Table` 的时候，主键中的第一个列是 `Partition Key`，第二个列是 `Cluster Key`。\n比如在下面的 CQL 中， `Keyspace` 是 `naive`, `Table` 是 `metrics`，`Partition Key` 是 `metric_name`,\n`Cluster Key` 是 `metrics_timestamp`。\n最内层的哈希表是 `{value: 10.2}`, 如果需要我们可以存更多的值，比如 `{value: 10.2, annotation: '新 bug 上线啦'}`。\n\n````sql\nCREATE TABLE IF NOT EXISTS naive.metrics (\n    metric_name text, metric_timestamp timestamp, value int,\n    PRIMARY KEY (metric_name, metric_timestamp))\nINSERT INTO naive.metrics (metric_name, metric_timestamp, value) VALUES (cpu, 2017/03/17:13:24:00:20, 10.2)    \nINSERT INTO naive.metrics (metric_name, metric_timestamp, value) VALUES (mem, 2017/03/17:13:24:00:20, 80.3)   \n````\n\n![Cassandra Time Series Data model](images/posts/cassandra-tsdb-model.png)\n\n上图显示了使用 Cassandra 存储时间序列数据时 naive 的表结构，\n`Cluster Key` 存储时间戳，列的值存储实际的数值。\n它 naive 之处在于序列和 Cassandra 的物理行是一一对应的。\n当单一序列的数据点超过 Cassandra 的限制(20亿)时就会崩溃。\n\n一个更加成熟的表结构是把一个时间序列按时间范围分区，(KairosDB 按照 3 周来划分，但是可以根据数据量进行不定长的划分)。\n为了存储分区的信息，需要一张额外的表。\n同时在 naive 里序列的名称只是一个简单的字符串，如果需要按照多种条件进行筛选的话，需要存储更多的键值对，并且对于这些键值对需要建立索引以提高查询速度。\n\n下面是完整的 KairosDB 的表结构，`data_points` 表对应的是 naive 里的 `metrics` 表。\n它看上去不像人写的，因为它就是直接导出的，KairosDB 使用的旧版 Cassandra 的 Thrift API 创建表结构，没有 `.cql` 文件。\n\n````sql\nCREATE TABLE IF NOT EXISTS data_points (\n    key blob,\n    column1 blob,\n    value blob,\n    PRIMARY KEY ((key), column1)\n) WITH COMPACT STORAGE;\nCREATE TABLE IF NOT EXISTS row_key_index (\n    key blob,\n    column1 blob,\n    value blob,\n    PRIMARY KEY ((key), column1)\n) WITH COMPACT STORAGE;\nCREATE TABLE IF NOT EXISTS row_key_time_index (\n    metric text,\n    row_time timestamp,\n    value text,\n    PRIMARY KEY ((metric), row_time)\n)\nCREATE TABLE IF NOT EXISTS row_keys (\n    metric text,\n    row_time timestamp,\n    data_type text,\n    tags frozen\u003cmap\u003ctext, text\u003e\u003e,\n    value text,\n    PRIMARY KEY ((metric, row_time), data_type, tags)\n)\nCREATE TABLE IF NOT EXISTS string_index (\n    key blob,\n    column1 blob,\n    value blob,\n    PRIMARY KEY ((key), column1)\n) WITH COMPACT STORAGE\n````\n\n有很多基于 Cassandra 的时间序列数据库，他们的结构大多相同，你可以看[这个列表]((https://xephonhq.github.io/awesome-time-series-database/?language=All\u0026backend=Cassandra))。\n我最近正在写一个如何用 Cassandra 和 Golang 自己写个时间序列数据库的博客，写好之后会把地址更新在这里。\n\n### InfluxDB\n\n[InfluxDB](https://github.com/influxdata/influxdb) 在存储引擎上[纠结了很久](https://docs.influxdata.com/influxdb/v1.3/concepts/storage_engine/)，\nleveldb, rocksdb, boltdb 都玩了个遍，最后决定自己造个轮子叫 `Time Structured Merge Tree`。\n\n`Time Structured Merge Tree` (TSM) 和 `Log Structured Merge Tree` (LSM) 的名字都有点误导性，关键并不是树，也不是日志或者时间，而是 `Merge`。\n写入的时候，数据先写入到内存里，之后批量写入到硬盘。读的时候，同时读内存和硬盘然后合并结果。\n删除的时候，写入一个删除标记，被标记的数据在读取时不会被返回。\n后台会把小的块合并成大的块，此时被标记删除的数据才真正被删除，这个过程叫做 `Compaction`。\n相对于普通数据，有规律的时间序列数据在合并的过程中可以极大的提高压缩比。\n\n下图是一个简化版的 TSM，每个块包含序列标识符，一组时间戳，一组值。\n注意时间戳和值是分开存储的，而不是交替存储的，所以 InflxuDB 是一个列存储。\nInfluxDB 会根据数据来选择压缩的方法，如果可以使用行程编码是最好的，\n否则会使用 [Gorilla]((https://github.com/dgryski/go-tsz)) 中提到的浮点数压缩方法以及变长编码。\n时间戳和数值一般会使用不同的压缩方法，因为时间戳大多是非常大的整数而数值是非常小的浮点数。\n\n````\nchunk\n--------------------------------------------------\n| id | compressed timestamps | compressed values |\n--------------------------------------------------\ntsm file\n-------------------------------------------------------------------\n| header | chunk 0 | chunk 1 | ... | chunk 10086 | index | footer |\n-------------------------------------------------------------------\n````\n\n## 热点话题\n\n### 低延迟\n\n时间序列数据库主要是用来分析的，所以提高响应速度对于诊断生产环境的问题是十分重要的。\n\n最直接的提速方法就是把所有数据都放在内存，Facebook 写了叫 [Gorilla](http://www.vldb.org/pvldb/vol8/p1816-teller.pdf) 的纯内存时间序列数据库发表在 VLDB 上，现在已经开源，改名为 [Beringei](https://github.com/facebookincubator/beringei)（都是猩猩...）。\n\n另一种提速的方法是提前聚合。因为查询中经常需要对一个很长的时间区间取一些粗粒度的值，比如`6月到8月每天的平均CPU使用率`。\n这些聚合值（均值，最大，最小) 都可以在存储数据的时候计算出来。\n[BtrDB](https://github.com/SoftwareDefinedBuildings/btrdb) 和 [Akumuli](https://github.com/akumuli/Akumuli)\n都在内部节点中存储聚合值，这样在很多查询中底层的节点不需要被访问就可以得到结果。\n\n同时一个好的数据传输格式也可以提高响应速度，虽然 JSON 被广泛使用，但是二进制的格式对于有大量数字的数据会显著的提升。\n[protobuf](https://github.com/golang/protobuf/) 可能会是一个更好的选择。\n\n### 处理旧数据\n\n很多时间序列数据都没有多大用处，特别是当系统长时间正常运行时，完整的历史数据意义并不大。\n所以有些数据库比如 [RDDTool](https://oss.oetiker.ch/rrdtool/) 和 [Graphite](https://graphiteapp.org/) 会自动删除高精度的数据，只保留低精度的。\n但是对于很多新的时间序列数据库，在聚合和删除大量旧数据的同时保证系统正常运行并不像删除一个本地文件那样简单。\n如果监控系统比被监控系统还不稳定就比较尴尬了。\n\n### 元数据索引\n\n时间序列的标识符是时间序列数据库里主要的元数据。\n[Heroic](https://github.com/spotify/heroic) 使用 Elasticsearch 来存储元数据，\n查询首先通过 Elasticsearch 来取得符合要求的序列标识符，之后从 Cassandra 根据标识符来读取对应的数据。\n但是维护一个完整的搜索引擎带来的运维压力和增加的通信时间都是不能忽视的。\n因此 InfluxDB 和 Prometheus 就[自己写了倒排索引]((https://fabxc.org/blog/2017-04-10-writing-a-tsdb/))来索引元数据。\n\n### Tracing\n\nInfluxDB 的人写了一篇博客 [Metrics are dead](https://www.influxdata.com/blog/metrics-are-dead/)，\n起因是在一个关于监控的会议 [Monitorama](http://monitorama.com/) 上有人说单纯的监控数据已经不能满足他们复杂的微服务架构了。\n于是 InfluxDB 的人反驳说并不是所有人都在使用大规模的分布式系统，对于很多简单的应用单纯的监控数据已经完全够用了。\n我的看法是**时间序列数据库是可以用来存 Trace 的**。\nTrace 是更加复杂的时间序列数据，把单纯的数值变成一个包含更多信息的对象，它就是一个 Trace。\n并且很多流行的 Tracer 的存储也是使用 Cassandra, 比如 [Zipkin](https://github.com/openzipkin/zipkin)，\nUber 的 [Jaeger](https://uber.github.io/jaeger/)。**更新:** InfluxDB 现在[已经支持存储 Trace 了](https://www.influxdata.com/blog/tracing-the-journey-of-a-transaction-as-it-propagates-through-a-distributed-system/)\n\n由于篇幅限制，有很多话题我们没有涉及，比如压缩，Pull vs Push, 写放大等，在以后的博客中会陆续介绍。\n\n## 参考\n\n- [Awesome Time Series Database](https://github.com/xephonhq/awesome-time-series-database)\n- [Akumuli](https://github.com/akumuli/Akumuli)\n- [Beringei](https://github.com/facebookincubator/beringei)\n- [BtrDB](https://github.com/SoftwareDefinedBuildings/btrdb)\n- [Gorilla](http://www.vldb.org/pvldb/vol8/p1816-teller.pdf)\n- [Grafana](https://github.com/grafana/grafana)\n- [Graphite](https://graphiteapp.org/)\n- [Heroic](https://github.com/spotify/heroic)\n- [InfluxDB](https://github.com/influxdata/influxdb)\n- [Jaeger - Tracer](https://uber.github.io/jaeger/)\n- [KairosDB](https://kairosdb.github.io/)\n- [OpenTSDB](http://opentsdb.net/)\n- [Prometheus](https://prometheus.io/)\n- [RRDTool](https://oss.oetiker.ch/rrdtool/)\n- [Timescale - TSDB using Postgres](http://www.timescale.com/)\n- [VividCortex - TSDB using MySQL](https://www.vividcortex.com/blog/2014/12/16/in-case-you-missed-it-building-a-time-series-database-in-mysql/)\n- [Zipkin - Tracer](https://github.com/openzipkin/zipkin)\n\n## License\n\n- This article is licensed under [CC BY-NC-SA 3.0](https://creativecommons.org/licenses/by-nc-sa/3.0/).\n- Please contact \u003cmarketing@dongyue.io\u003e for commerical use.\n","cover":"","link":"时间序列数据库漫谈.html","preview":"\u003cp\u003e时间序列数据库基本概念和热点话题\u003c/p\u003e\n","title":"时间序列数据库漫谈"},{"content":"\n\nThis blog is written for fellow students at [dongyueweb](https://github.com/dyweb),\nso its targeted readers are people who have taken database class and want to know about time series database (TSDB).\n\nTable of content\n\n- What is time series database (TSDB)\n- Time series data model\n- Evolve of time series database\n- Types of time series database\n  - KairosDB\n  - InfluxDB\n- Hot topics in time series database\n  - Fast response\n  - Retention\n  - Meta data indexing\n  - Tracing\n\n## What is time series database (TSDB)\n\nTime series database (TSDB) is relative new compared with RDBMS, NoSQL, even NewSQL.\nHowever it is becoming trending with the growth of system monitoring and internet of things.\nThe [wiki](https://en.wikipedia.org/wiki/Time_series) definition of time series data is *a series of data points indexed (or listed or graphed) in time order*. When it comes to TSDB, I prefer my own definition: **store client history in server for analysis**.\nTime series data is history, it's **immutable**, **unique** and **sortable**. \nFor instance, `the CPU usage at 2017-09-03-21:24:44 is 10.02% for machine-01 in us-east region`, \nit won't change overtime like bank account balance, there will be no update once it's generated, \nthe CPU usage at next second, or from different machine are different data points. \nAnd **the order of data arriving at server does not effect correctness** because you can remove the duplicate and sort by client timestamp.\nClients of TSDB send their history to sever and is still functional when the server is down, \n**sending data to TSDB is not critical for many clients**;\nA http server's main job is serving content instead of reporting status code to TSDB.\nHowever, RDBMS is treated as single source of truth and effect client's critical decision making. \nThis lead to very different read and write pattern. \nFor instance, banking application need to query database for user's balance before proceed by reading and updating a single record.\nBut most TSDB clients are either write only (collectors) or read only (dashboard and alerting system). \nAnd when they read, they read in large batch, `show CPU usage of last 1h` is used more often than `show CPU usage at 2017-09-03-21:24:44` \nbecause time series data is not that useful without its context.\n\nTime series data is so different from what popular DBMS used to deal with that people are forced to use their favorite DB in very different ways (i.e. [VividCortex with MySQL](https://www.vividcortex.com/blog/2014/12/16/in-case-you-missed-it-building-a-time-series-database-in-mysql/), [Timescale with Postgres](http://www.timescale.com/)). \nSome decided for special problem special solution is needed, so many TSDBs are written from scratch ([Graphite](https://graphiteapp.org/), \n[InfluxDB](https://github.com/influxdata/influxdb) etc.) without dependencies to existing databases.\n\n## Evolve of time series database\n\nThere are [too many time series databases](https://xephonhq.github.io/awesome-time-series-database/?language=All\u0026backend=All),\nso I just list databases that I personally considered as milestone in the evolving of time series database, \nfeel free to comment the pieces I missed, I can't find the real initial release of many databases so I just use the oldest on github.\n\n- 1999/07/16 [RRDTool First release](https://en.wikipedia.org/wiki/RRDtool)\n- 2009/12/30 [Graphite 0.9.5](https://github.com/graphite-project/graphite-web/releases/tag/0.9.5)\n- 2011/12/23 [OpenTSDB 1.0.0](https://github.com/OpenTSDB/opentsdb/releases/tag/v1.0.0)\n- 2013/05/24 [KairosDB 1.0.0-beta](https://github.com/kairosdb/kairosdb/releases/tag/v1.0.0-beta2a)\n- 2013/10/24 [InfluxDB 0.0.1](https://github.com/influxdata/influxdb/releases/tag/v0.0.1)\n- 2014/08/25 [Heroic 0.3.0](https://github.com/spotify/heroic/releases/tag/0.3.0)\n- 2017/03/27 [TimescaleDB 0.0.1-beta](https://github.com/timescale/timescaledb/releases/tag/0.0.1-beta)\n\n[RRDTool](https://oss.oetiker.ch/rrdtool/) was created to graph network traffic, it ships with graphing tool while modern TSDB normally depends on [Grafana](https://github.com/grafana/grafana) for graphing. \n[Graphite](https://graphiteapp.org/) was created later using python instead of C like RRDTool, its storage engine is called [Whisper](https://github.com/graphite-project/whisper), it's much powerful when it comes to data processing and query, however it does not scale well.\n[OpenTSDB](http://opentsdb.net/) from Yahoo! solves the scale problem by using HBase.\n[KairosDB](https://kairosdb.github.io/) was a fork for OpenTSDB to support Cassandra as an alternative backend, but then they found being compatible with HBase limit the potential of Cassandra, so they dropped HBase and use Cassandra only. \nIronically, [recent release of OpenTSDB](http://opentsdb.net/docs/build/html/new.html) added support for Cassandra.\nThen [Heroic](https://github.com/spotify/heroic) came out because they are [not satisfied with KairosDB's performance and direction](https://labs.spotify.com/2015/11/16/monitoring-at-spotify-the-story-so-far/).\n[InfluxDB](https://github.com/influxdata/influxdb) started with full open source, \nbut then close sourced their cluster version because they need to keep the company running, there is a interesting talk called [The Open Source Database Business Model is Under Siege](https://www.youtube.com/watch?v=Kvf5jWZjw0U) during Percona Live which features [a time series session](https://www.percona.com/live/17/program/schedule/time-series).\n[TimeScaleDB](http://www.timescale.com/) is based on PostgreSQL with a plugin instead of special schema. \n\n## Time series data model\n\nTime series data can be split into two parts, **series** and **data points**.\nSeries is the identifier, like `CPU usage for machine-01 in us-east region`, \ndata points are an array of points where each point is a timestamp and value.\n\nFor series, the main goal is the extensibility for post processing (searching, filtering etc.).\ni.e. If you want `CPU usage of all machines in us-east region`,\nthe identifier of series `CPU usage for machine-01 in us-east region` is `name=cpu.usage machine=machine-01 region=us-east`, \nand the query becomes `name=cpu.usage machine=* region=us-east`.\nIt order to deal with large amount of series and wildcard matching, (inverted) index is needed,\nsome chose to use external search engine like [Heroic](https://github.com/spotify/heroic) is using Elasticsearch.\nSome chose to write their own like [InfluxDB](https://github.com/influxdata/influxdb), [Prometheus](https://prometheus.io/).\n\nFor data points there are two models, an array of points `[{t: 2017-09-03-21:24:44, v: 0.1002}, {t: 2017-09-03-21:24:45, v: 0.1012}]` \nor two arrays for timestamp and values respectively `[2017-09-03-21:24:44, 2017-09-03-21:24:45], [0.1002, 0.1012]`.\nThe former is row store, the latter is column store (not to be confused with column family).\nWhen building TSDB on top of existing databases ([Cassandra](https://xephonhq.github.io/awesome-time-series-database/?language=All\u0026backend=Cassandra), [HBase](https://xephonhq.github.io/awesome-time-series-database/?language=All\u0026backend=HBase) etc.), the former is used more,\nwhile for TSDB written from scratch, the latter is more popular, TSDB is actually a subset of OLAP and columnar format brings higher compression ratio and query speed.\n\n## Types of time series databases\n\nTime series databases can be split into two types, existing databases with time series specific special schema or databases built for time series data from scratch. \nWe use KairosDB and InfluxDB as example for following discussion. \nA lot of TSDB are [built on top of Cassandra](https://xephonhq.github.io/awesome-time-series-database/?language=All\u0026backend=Cassandra), \n[KairosDB](https://kairosdb.github.io/) is the pioneer of them.\n[InfluxDB](https://github.com/influxdata/influxdb) has tried many backends until they came up with their `Time Structured Merge Tree`.\n\n### KairosDB\n\nBefore dive into KairosDB, let's warm up using a simplified version called [Xephon-K](https://github.com/xephonhq/xephon-k).\n[Xephon-K](https://github.com/xephonhq/xephon-k) is a multi backend time series database I wrote for testing out different mechanism of building TSDB. Its immature Cassandra backend is simple and modeled after [KairosDB](https://kairosdb.github.io/).\n\nIf you are not familiar with Cassandra, here is a brief introduction.\nCassandra (C*) is a column family NoSQL database modeled after BigTable, people sometimes call it **wide column**. \nYou can think column family as a map of map of map. It's a row store, not a column store.\nWe can match some concept of Cassandra with RDBMS's.\n`Keyspace` in C* is database in RDBMS, i.e. your blog and ecommerce application use same MySQL Server but create different database for isolation.\n`Table` in C* is a map and `Partition Key` is its key, also known as (physical) row key, which is used to partition data to different nodes.\nThe value of the top level map is also map, and its key is the `Cluster key` (column), its value is also a map.\nWhen creating a table in CQL, the first column in primary key is partition key and the second is cluster key. i.e. In the following CQL, \n`Keyspace` is `naive`, `Table` is `metrics`, `Partition Key` is `metric_name`, `Cluster Key` is `metrics_timestamp`, \nthe inner most map is `{value: 10.2}`, we can have more than one keys for it if needed, i.e. `{value: 10.2, annotation: 'new app deployed'}`\n\n````sql\nCREATE TABLE IF NOT EXISTS naive.metrics (\n    metric_name text, metric_timestamp timestamp, value int, \n    PRIMARY KEY (metric_name, metric_timestamp))\nINSERT INTO naive.metrics (metric_name, metric_timestamp, value) VALUES (cpu, 2017/03/17:13:24:00:20, 10.2)    \nINSERT INTO naive.metrics (metric_name, metric_timestamp, value) VALUES (mem, 2017/03/17:13:24:00:20, 80.3)   \n````\n\n![Cassandra Time Series Data model](images/posts/cassandra-tsdb-model.png)\n\nThe figure above shows a naive schema when using Cassandra to store time series data, \n`Cluster key` is used to store timestamp and column value is the actual value.\nIt is naive because series and Cassandra's physical row is a one-to-one mapping, it won't scale when a single series grows larger than the hard limit of Cassandra (2 billion columns). \n \nA more mature schema would partition a single series by time range (might not be fixed, KairosDB use fixed 3 week time range) into several physical rows, an extra table is needed to keep this partition info. \nAlso the series name in naive schema is just a simple string, in order to filter series by different criteria, attributes (tags) need to be stored, and another table as index is needed to avoid iterate all the series. \n\nKairosDB's schema is listed below, the `data_points` table is same as `metrics` table in naive schema except `key` is \nnot for human like `metric_name` does. The naming of schema looks strange because it is dumped from Cassandra's shell (cqlsh), \nKairosDB didn't use a cql file to create schema like many other does because it was using the old thrift API.\n\n````sql\nCREATE TABLE IF NOT EXISTS data_points (\n    key blob,\n    column1 blob,\n    value blob,\n    PRIMARY KEY ((key), column1)\n) WITH COMPACT STORAGE;\nCREATE TABLE IF NOT EXISTS row_key_index (\n    key blob,\n    column1 blob,\n    value blob,\n    PRIMARY KEY ((key), column1)\n) WITH COMPACT STORAGE;\nCREATE TABLE IF NOT EXISTS row_key_time_index (\n    metric text,\n    row_time timestamp,\n    value text,\n    PRIMARY KEY ((metric), row_time)\n)\nCREATE TABLE IF NOT EXISTS row_keys (\n    metric text,\n    row_time timestamp,\n    data_type text,\n    tags frozen\u003cmap\u003ctext, text\u003e\u003e,\n    value text,\n    PRIMARY KEY ((metric, row_time), data_type, tags)\n)\nCREATE TABLE IF NOT EXISTS string_index (\n    key blob,\n    column1 blob,\n    value blob,\n    PRIMARY KEY ((key), column1)\n) WITH COMPACT STORAGE\n````\n\nThere are many more Cassandra based time series databases, they share very similar schema, you can find in [awesome time series database](https://xephonhq.github.io/awesome-time-series-database/?language=All\u0026backend=Cassandra). I am writing a new blog for more detailed survey on TSDB using Cassandra and how to write your own in Golang, I will update the link here once it's finished.\n\n### InfluxDB\n\n[InfluxDB](https://github.com/influxdata/influxdb) has [struggled a long time for their storage engine](https://docs.influxdata.com/influxdb/v1.3/concepts/storage_engine/) (leveldb, rocksdb, boltdb) before they settled with their time structured merge tree (TSM Tree). It can be separate into two parts, index for series identifiers and store for data points, we only focus on data points.\n\nTime structure merge tree (TSM), is a little bit misleading as log structured merge tree (LSM). \nThe key concept for both TSM and LSM is nor log or tree or time,\nit's **merge**. When write, data is stored in memory and then flushed to disk in large batch. When read, first read from memory, then read from disk and merge the result. When delete, a tombstone is added, and data with tombstone is not returned when read. In background, small chunks are merged into big chunks and items marked as deleted are truly removed to save disk space and speed up future query, this background procedure is called compaction. For time series data, compaction may increase compression ratio a lot for very regular data.\n\nA simplified version of TSM file is illustrated below, each chunk contains the series identifier, timestamps and values. \nNote that timestamps and values are stored separately instead of interleaved, which is why InfluxDB say they are using column format.\nInfluxDB use adaptive compression for data, it will loop through the data to see if it can be run length encoded, otherwise fallback to \n[Gorilla's](https://github.com/dgryski/go-tsz) or variable length encoding. Timestamps and value use different compression codec because\ntimestamps are normally very big integers (unix timestamp in millisecond or nanosecond) while value are normally small integer or float.\n\n````\nchunk\n--------------------------------------------------\n| id | compressed timestamps | compressed values |\n--------------------------------------------------\ntsm file\n-------------------------------------------------------------------\n| header | chunk 0 | chunk 1 | ... | chunk 10086 | index | footer |\n-------------------------------------------------------------------\n````\n\n## Hot topics in Time series databases\n\n### Fast response\n\nTime series database is used for analysis, and people don't want to wait in front of dashboard when production system is failing and \nuser's complain phone coming in, so fast response is a base requirement for any production ready time series database.\n\nThe most straight forward way is to put data into memory as much as possible.\nFacebook built [Gorilla](http://www.vldb.org/pvldb/vol8/p1816-teller.pdf), now open sourced as [Beringei](https://github.com/facebookincubator/beringei), \nand its main contribution is using time series specific compression to store more data in memory.\n\nAnother way for speed up is pre-aggregation, also known as roll up. Because query often involve a long time range with coarse granularity, like\n`average daily cpu usage from June 1 to Aug 1`, those aggregations (average, min, max) can be computed when ingesting data, [BtrDB](https://github.com/SoftwareDefinedBuildings/btrdb) and [Akumuli](https://github.com/akumuli/Akumuli) store aggregation in upper level tree nodes so fine grained data won't be loaded when query is coarse grained.\n\nA proper ingest format could also reduce response time for both read and write, JSON is widely used, but Binary format is much better than textual format when a lot of number is involved, [protobuf](https://github.com/golang/protobuf/) could be a good choice.\n\n\u003c!-- ### Compression --\u003e\n\n### Retention\n\nNot all time series data is useful all time, if the system has been working well for the last two month, fine grained data can be dropped and only coarse grained is kept. \nThis is the default behavior of [RDDTool](https://oss.oetiker.ch/rrdtool/) and [Graphite](https://graphiteapp.org/), \nbut not the case for many newer scaled TSDB.\nDelete a file on local disk is easy but update a large amount of data in a distributed environment requires more caution to keep the system up all time, you don't want your monitoring systems failed before the system it is monitoring failed.\n\n\u003c!-- Also should the aggregated data get computed when data comes in or  --\u003e\n\n### Meta data indexing\n\nSeries identifier in general is the only meta data in time series database.\nDatabases like [Heroic](https://github.com/spotify/heroic) use ElasticSearch to store meta data, \nquery first goes to elasticsearch to retrieve the id for series, then data is loaded from Cassandra using id.\nA full search engine as Elasticsearch is powerful for sure, but the overhead of maintain another system and time spent\ncoordinating and communicating between two system can't be ignored. \nAlso some TSDB specific optimization may not be available when you don't have full control over metadata index building and storage.\nSo InfluxDB and Prometheus [wrote their own inverted index for indexing meta data](https://fabxc.org/blog/2017-04-10-writing-a-tsdb/).\n\n\u003c!-- ### Reduce write amplification --\u003e\n\u003c!-- ### Streaming --\u003e\n\u003c!-- Streaming has been hot for a long time, you must have heard Storm, Spark Streaming, Kafka etc. --\u003e\n\n### Tracing\n\nFolks from InfluxDB wrote a blog called [Metrics are dead](https://www.influxdata.com/blog/metrics-are-dead/) \nbecause during a conference for monitoring called [Monitorama](http://monitorama.com/) people say metrics can't provide enough insight as tracing does. \n(You can go to [OpenTracing](http://opentracing.io/) if you want to know more about tracing, and take a look at google's [Dapper paper](https://research.google.com/pubs/pub36356.html))\nTheir argument is tracing is for large scale distributed system, but there are many monolithic applications where metrics is enough (so metrics is not dead and you should use InfluxDB).\nI agree with them on the over emphasis of micro services, however my argument is **many time series database can be transfered into a tracing database**. \nTrace is a complex version of time series data points, \nif your value in a point is no longer a float value but a json payload with fields like parent span id, duration, it is a trace. \nOf course schema design, compression all need a lot of change, but many popular tracing solution like [Zipkin](https://github.com/openzipkin/zipkin)\n, Uber's [Jaeger](https://uber.github.io/jaeger/) is also using Cassandra like many TSDB do, there could be a middle ground.\n**Update:** InfluxDB already [tried to integrate Zipkin with their TICK stack](https://www.influxdata.com/blog/tracing-the-journey-of-a-transaction-as-it-propagates-through-a-distributed-system/)\nI spent too much time writing this blog.\n\nBecause the length of the blog we can't cover other hot topics like Compression, Pull vs Push, Streaming, Reduce write amplification etc,\nthey will be covered in future blogs.\n\n## Reference\n\n- [Awesome Time Series Database](https://github.com/xephonhq/awesome-time-series-database)\n- [Akumuli](https://github.com/akumuli/Akumuli)\n- [Beringei](https://github.com/facebookincubator/beringei)\n- [BtrDB](https://github.com/SoftwareDefinedBuildings/btrdb)\n- [Gorilla](http://www.vldb.org/pvldb/vol8/p1816-teller.pdf)\n- [Grafana](https://github.com/grafana/grafana)\n- [Graphite](https://graphiteapp.org/)\n- [Heroic](https://github.com/spotify/heroic)\n- [InfluxDB](https://github.com/influxdata/influxdb)\n- [Jaeger - Tracer](https://uber.github.io/jaeger/)\n- [KairosDB](https://kairosdb.github.io/)\n- [OpenTSDB](http://opentsdb.net/)\n- [Prometheus](https://prometheus.io/)\n- [RRDTool](https://oss.oetiker.ch/rrdtool/)\n- [Timescale - TSDB using Postgres](http://www.timescale.com/)\n- [VividCortex - TSDB using MySQL](https://www.vividcortex.com/blog/2014/12/16/in-case-you-missed-it-building-a-time-series-database-in-mysql/)\n- [Zipkin - Tracer](https://github.com/openzipkin/zipkin)\n\n## License\n\n- This article is licensed under [CC BY-NC-SA 3.0](https://creativecommons.org/licenses/by-nc-sa/3.0/).\n- Please contact \u003cmarketing@dongyue.io\u003e for commerical use.\n","cover":"","link":"introduction_to_time_series_database.html","preview":"\u003cp\u003eAn introduction to time series database basic concepts and hot topics\u003c/p\u003e\n","title":"Introduction to Time Series Database"},{"content":"\n\n#### 转载自 [gaocegege 的博客](http://gaocegege.com/Blog/%E9%98%85%E8%AF%BB/sre-0)\n\n## SRE 介绍\n\nSRE，全称是 Site Reilability Engineer，是一个类似于运维，但是跟传统运维不一样的职业，更加偏向于 DevOps。谷歌在 [SRE-谷歌运维解密](https://book.douban.com/subject/26875239/) 一书中分享了 SRE 的工作职责，以及谷歌在自己的运维工作中的一些经验。\n\n## 本文介绍\n\n这篇博客是系列文章中的第一篇，主要分享在阅读这本书时的一些感想。这本书在我看来更加适合在分布式领域或者在运维领域工作的工程师阅读，对于一个还在念书，没有完整接触过分布式系统实现的新手来说，有些过早了。因此就当是抛砖引玉，随便写写吧。\n\n这次关注的是书中的第六章，分布式系统的监控。\n\n## 关于作者\n\n第六章的作者是 [Rob Ewaschuk](https://www.linkedin.com/in/robewaschuk)。作者主要工作的领域是分布式存储，而且在自我介绍中写道自己在谷歌干的很过瘾，16-17年是不打算换工作的。O'Reilly 摘录了他在 SRE 一书中关于分布式监控的部分，做了一本电子书 [Monitoring Distributed Systems](http://www.oreilly.com/webops-perf/free/monitoring-distributed-systems.csp)。\n\n## 阅读之前\n\n在读文章之前，我对监控的了解非常浅薄。因为无论是在学校还是在之前实习，都没有涉及到对生产系统进行监控的工作。在念了研究生之后，稍微了解了一些关于分布式监控的知识。[Dapper, a Large-Scale Distributed Systems Tracing Infrastructure](https://static.googleusercontent.com/media/research.google.com/zh-CN//pubs/archive/36356.pdf) 是谷歌在 2010 年发表的论文，是关于其内部的分布式 tracing 系统的一个介绍性的论文。Tracing 在我的理解是细粒度监控中很关键的一部分。点评开源了一套这样的系统 [CAT](https://github.com/dianping/cat)。这些系统的作用就是跟踪系统相互之间的调用。比如 Web 前端调用了后端，就会生成一个从前端指向后端的 trace 记录。业界比较常见的实现是埋点或者修改字节码，前者更加可行。在阅读之前，对于分布式监控的了解也就仅限于此了。\n\n虽说读过相关论文，但是并没有真实使用过，最多就是去过点评，见过点评的 CAT 的 dashboard 是长什么样子的。\n\n## 正文\n\n全文中提到的一些东西让我非常感兴趣。其中有一句话：\n\n\u003e我们会避免任何『魔法』系统--例如视图自动学习阈值或者自动检测故障原因的系统。\n\n之前在去大众点评学习 CAT 系统时，听他们说下一步发展规划中，就有利用机器学习来学习阈值和原因的想法。我认为谷歌在为什么要保持监控系统简单时没有说清楚，这可能是跟他们的监控规模和信奉的哲学有关。他们把这类复杂的有各种特性的系统称为『魔法』系统，因为我也没有什么发言权。但是在我看来，随着复杂性的上升，引入机器学习等等是自动化的新阶段。现在可能人工的方式或者硬编码等等方式还是可以操作的，可能谷歌考虑到监控系统要尽可能稳定吧。但是机器学习可以更好地取代人工，就像在容量规划方面，我始终认为机器学习会比经验估计的更准。\n\n书中写了四个谷歌认为的黄金监控指标，分别是延迟、流量、错误和饱和度。对于延迟，他们提到的一点对我来说特别具有启发性，那就是要区分成功请求和错误请求的延迟。这两类请求有着不同的模式，是不能混为一谈的。之前用过的少数几个监控的工具都没有区分正确与错误请求的能力。这一点是在看了这本书后才学到的。\n\n还有一个比较有趣的指标，是饱和度。饱和度是指服务容量有多满，一般是用瓶颈资源的使用率来衡量。这样衡量饱和度的方式很取巧，之前没有过工程经验，都是各种指标全看一遍，最后看哪个资源不够用了，就断定服务满载了。如果事先判断好是 Memory-bound 还是 CPU-bound 类型的服务，然后每次只需要看对应的瓶颈资源就好了。\n\n关于长尾问题，谷歌给出了一种监控的方法，使用直方分布图而不是平均值来进行展示。因为可能一小部分请求导致了长尾，但是平均值是看不出这个问题的。\n\n在监控系统构建后，有一个值得考虑的问题，是短期可用性与长期可用性的冲突。短期的可用性体现在对问题的及时修复上，而长期的可用性在于对系统造成问题的根源的消除上。看起来这两者是统一的，但是其实是冲突的。人的精力是有限的，如果一直在处理 On-Call 的问题，那必然会导致缺少时间投入到根源性问题的解决上，这时需要权衡，放弃一些 On-Call 非核心的问题，去优化系统，提高长期预期的可用性。\n\n## 下文预告\n\n下一篇文章将会谈谈有关发布工程（Releasing Engineering）的事情。\n\n## 系列文章\n\n* [Google SRE 阅读笔记(1)-监控](http://blog.dongyueweb.com/google_sre_%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%281%29-%E7%9B%91%E6%8E%A7.html)\n\n## License\n\n- This article is licensed under [CC BY-NC-SA 3.0](https://creativecommons.org/licenses/by-nc-sa/3.0/).\n- Please contact \u003cmarketing@dongyue.io\u003e for commerical use.\n","cover":"","link":"google_sre_阅读笔记(1)-监控.html","preview":"\u003cp\u003eSRE，全称是 Site Reilability Engineer，是一个类似于运维，但是跟传统运维不一样的职业，更加偏向于 DevOps。谷歌在 \u003ca href=\"https://book.douban.com/subject/26875239/\"\u003eSRE-谷歌运维解密\u003c/a\u003e 一书中分享了 SRE 的工作职责，以及谷歌在自己的运维工作中的一些经验。\u003c/p\u003e\n","title":"Google SRE 阅读笔记(1)-监控"},{"content":"\n\n今天为东岳搭建了一个饥荒的服务器，并不是特别复杂。饥荒对于服务器的要求是：\n\n```text\nInternet(Upload) = 8Kbytes/player/s\nRam = around 65Mbytes/player\nCPU = N/A\nVCRedist_2008 (x86)\n```\n\n因此选定配置的时候要计算下，服务器的最低配置要求。因为考虑到我们的玩家数最多也就20人左右，长期在线人数能在3-4人就不错了，因此一台1核2G内存的机器就可以满足我们的要求了。\n\n我们中的绝大多数玩家，都是在华东地区的，而只有一个美帝玩家。因此在服务器的选择上，华东节点是最合适的。在考察了包括阿里云、美团云、青云、腾讯云、Hyper.sh 在内的众多云服务提供商后，选择了最便宜的腾讯云。就流量来说，基本所有的服务商都是一个价钱，但是服务器的价格从 85 到 125 不等。Hyper.sh 因为没有华东节点，就没有关注价格。因为 steam 的 cmd 运行需要 32 位的环境，而且服务器的内存没有超过 4G，因此选择了 32位 Ubuntu 16.04.1 LTS。因为选择的云服务提供商和系统都很大众，因此在过程中并没有遇到什么坑。\n\n## 安装 steam 和 饥荒\n\n按照官方的文章，没什么好说的，不过为了简单，在搭建的过程中省略了创建用户的过程，直接在默认的用户目录下进行的。还有就是需要安装两个在官方教程中没有写到的东西：xfonts-75dpi 和 xfonts-100dpi，不然在运行 steamcmd.sh 的时候会报错 `Steam needs to be online to update`。\n\n```bash\nsudo apt-get install libgcc1\nsudo apt-get install xfonts-75dpi xfonts-100dpi\nmkdir ~/steamcmd\ncd ~/steamcmd\nwget https://steamcdn-a.akamaihd.net/client/installer/steamcmd_linux.tar.gz\ntar -xvzf steamcmd_linux.tar.gz\n./steamcmd.sh\nlogin anonymous\n# replace \u003cuser\u003e with your current user. if you use qcloud, ubuntu is the default username.\nforce_install_dir /home/\u003cuser\u003e/steamapps/DST\napp_update 343050 validate\nquit\ncd /home/steam/steamapps/DST/bin/\n```\n\n## 添加配置文件\n\n至此游戏服务器的所有二进制和依赖都安装好了，接下来需要进行配置。在 `/home/\u003cuser\u003e/.klei/DoNotStarveTogether/Cluster_1` 目录下需要建立两个文件，cluster.ini 和 cluster_token.txt。前者是对服务器的配置，后者是在饥荒的客户端游戏中生成的一个 token，猜测会用来校验玩家是否在使用正版游戏，等等。\n\ncluster.ini 文件内容很简单：\n\n```text\n[network]\ncluster_name = \u003ccluster_name\u003e\ncluster_intention = cooperative\ncluster_description = \u003ccluster_description\u003e\ncluster_port = 10999\ncluster_password = \u003cpasswd\u003e\n\n[misc]\nconsole_enabled = true\n\n[gameplay]\nmax_players = \u003cmax_players_num\u003e\npvp = false\ngame_mode = endless\npause_when_empty = true\n```\n\ncluster_token.txt 文件的内容需要用饥荒的客户端来生成，输入 `~` 打开游戏内置的 console，输入 `TheNet:GenerateClusterToken()`，不同系统会在不同位置生成一个 token：\n\n```text\nWindows:\n/My Documents/Klei/DoNotStarveTogether/cluster_token.txt\n\nLinux:\n ~/.klei/DoNotStarveTogether/cluster_token.txt\n\nMac OS X:\n~/Documents/Klei/DoNotStarveTogether/cluster_token.txt\n```\n\n然后将文件内容拷贝到 `/home/\u003cuser\u003e/.klei/DoNotStarveTogether/Cluster_1/cluster_token.txt` 中就行。\n\n## 运行\n\n```bash\n/home/\u003cuser\u003e/steamapps/DST/bin/dontstarve_dedicated_server_nullrenderer\n```\n\n官方推荐使用 screen 来维持服务器在退出 ssh 连接后依然在运行，但你喜欢怎么做就随便了。\n\n## Reference\n\n* [Don’t Starve Together（饥荒）服务器搭建](https://www.nevermoe.com/?p=695)\n\n## License\n\n- This article is licensed under [CC BY-NC-SA 3.0](https://creativecommons.org/licenses/by-nc-sa/3.0/).\n- Please contact \u003cmarketing@dongyue.io\u003e for commerical use.\n","cover":"","link":"在32位_ubuntu_16.04.1_lts_上安装饥荒服务器.html","preview":"\u003cp\u003e今天为东岳搭建了一个饥荒的服务器，并不是特别复杂。\u003c/p\u003e\n","title":"在32位 Ubuntu 16.04.1 LTS 上安装饥荒服务器"},{"content":"\n\n## 简介\n\n[Ayi](https://github.com/dyweb/Ayi) 是一个跨平台的命令行工具，类似于[busybox](https://busybox.net/about.html)。\n开始于 2015 年 7 月。主要目的是为了方便配置环境和解决各种由于配置环境导致的问题，比如:\n\n\u003e - 我这里跑的好好的，怎么到了你那(服务器上)就挂了\n\u003e - 我用 Mac 自带的 PHP 和 Apache 就挺好，我不用 Vagrant 和 Nginx\n\u003e - 我就想用 Windows 下的一键安装包\n\n考虑到没钱给大家每人配个 Mac，以及东岳的男女比例。\n我们需要一个跨平台的配置环境和收集环境信息的工具，用于**快速**的解决上述问题。\n\n## 技术选型\n\n在选择 Ayi 使用的技术时主要考虑的是以下几个问题\n\n- 跨平台\n- 可维护性\n- 对于东岳其他项目的帮助\n\n\u003c!-- TODO:找不到是哪个 issue 了，倒是找到了 commit https://github.com/dyweb/Ayi/commit/3a96921ccb6b5edb7c294e2a1eab2b9e63cc130b --\u003e\n最开始和咩的考虑是使用 shell 来进行操作， 但是 shell 的问题在于很难维护，基本不可能测试。\n东岳 shell 用的很少，并且 shell 对于其他项目帮助十分有限。\n\n之后考虑到 PHP, python, java 都需要运行时，C/C++ 写起来太累， Rust 没人会 (那会还没有 Ivan 和 Codeworm)，\n就选择了 Golang，当时版本是 1.5。\n\nGolang 的主要优点是\n\n- 跨平台 \u0026 交叉编译\n- 简洁的包管理\n- 性能好，可以用来改进东岳现有的纯 PHP 服务端体系\n- 一个活跃的社区，PHP 沉浸在 CMS 和抄 Rails 中不能自拔，JS 日新月异\n- Google 老爹\n\n## 主要问题\n\n- 人太少，基本只有 @at15 (我) 一个人\n- 需求不是很明确\n- 对 Golang 语言本身很不熟悉\n- Golang 的一些工具链不是很成熟，比如不支持依赖的 vendor 。\n\n但是由于项目拖了很长时间，后面三个问题基本都解决了\n\n- 主要需求是\n  - 生成器\n  - 环境检查\n  - [git 操作的简化](https://github.com/dyweb/Ayi/tree/master/app/git)\n  - [makefile 类似的自动化工具](https://github.com/dyweb/Ayi/tree/master/util/runner)\n  - [静态 web 服务器](https://github.com/dyweb/Ayi/tree/master/app/web)\n  - [进程管理](https://github.com/dyweb/Ayi/pull/64)\n  - waka time 服务器\n  - 文件传输\n- go 的版本从 1.5 跳到了 1.7。原生支持 vendor 并且有了很多更好的依赖管理工具，比如 [glide](https://github.com/Masterminds/glide)\n\n第一个问题的话，基本无解，目前东岳经常写 Golang 的人好像只有我和策策。策策有空就要去陪妹子，自然不可能陪我来填坑。\n(要有妹子的话我还会去填坑么?)\n\n## 实现的功能\n\n### Git 操作的简化\n\n前提是：你习惯使用 Golang 的 workspace，有关 workspace 我在以前东岳的讲座中[有提到](http://dongyueweb.com/course/web/2016_Spring/environment/slide.html#/4) (btw: 按方向键`下`而不是`右`)。我个人的工作区是这样的 (`cd ~/workspace \u0026\u0026 tree -L 4`)。\n\n````\n├── bin\n│   ├── Ayi\n│   ├── glide\n│   └── ink\n├── pkg\n│   └── linux_amd64\n│       └── github.com\n│           └── dyweb\n└── src\n    └── github.com\n        ├── at15\n        │   └── at15.github.io\n        ├── dyweb\n        │   ├── Ayi\n        │   └── blog\n        └── xephonhq\n            └── xephon-b\n````\n\n当使用 `git clone` 时后面必须跟完整的 remote 地址，并且默认 clone 到当前文件夹下，而使用\n`Ayi git clone` 地址可以是浏览器地址，并且根据配置文件，可以支持非默认端口的 ssh，比如东岳的 GitLab。\n从下面的输出可以看到 `Ayi git clone github.com/at15/at15.gihub.io` 被展开成了\n`git clone git@github.com:at15/at15.github.io.git /home/at15/workspace/src/github.com/at15/at15.github.io`。\n\n````\nat15@pc4038:~/workspace|⇒  Ayi git clone github.com/at15/at15.github.io\nINFO[0000] git clone git@github.com:at15/at15.github.io.git /home/at15/workspace/src/github.com/at15/at15.github.io pkg=a.a.git\nCloning into '/home/at15/workspace/src/github.com/at15/at15.github.io'...\nremote: Counting objects: 435, done.\nremote: Total 435 (delta 0), reused 0 (delta 0), pack-reused 435\nReceiving objects: 100% (435/435), 3.56 MiB | 1.64 MiB/s, done.\nResolving deltas: 100% (234/234), done.\nChecking connectivity... done.\nINFO[0002] Sucessfully cloned to: /home/at15/workspace/src/github.com/at15/at15.github.io pkg=a.cmd\n````\n\nbtw: `Ayi` 的 log 组件看上去很像 [logrus](https://github.com/sirupsen/logrus)，但其实是[自己的轮子](https://github.com/dyweb/Ayi/pull/60)\n\n### 自动化\n\n自动化部分很类似 `npm run`，但是主要有以下区别\n\n- 使用 yaml 而不是 json, json 不支持注释，而且即使使用支持注释的 parser，编辑器也会有提示\n- 支持一个指令对应一系列命令, 类似 Travis 等 CI 的配置文件\n- 目前[新的重构](https://github.com/dyweb/Ayi/pull/64)可能会把它改成类似 + 的工具\n\n````\ndebug: true\ndep-install:\n    - go get github.com/at15/go.rice/rice\n    - go get github.com/mitchellh/gox\n    - glide install\ninstall:\n    - go build -o Ayi\n    - rice append -i github.com/dyweb/Ayi/app/web --exec Ayi\n    - sh -c \"mv Ayi $GOPATH/bin/Ayi\"\ntest:\n    - go install\n    - sh -c \"go test -v -cover $(glide novendor)\"\nscripts:\n    build: gox -output=\"build/Ayi_{{.OS}}_{{.Arch}}\"\n````\n\n内置指令如`install`, `test` 跟 `Ayi run \u003cscript-name\u003e` 都是使用 `util/runner`。\n目前准备把 runner 做成一个通用的 package，\n因此[又在重构](https://github.com/dyweb/Ayi/pull/64)来增加如下的功能\n\n- 类似 [Ansible](https://www.ansible.com/) 的更丰富的配置\n- 类似[ PM2](http://pm2.keymetrics.io/) 和 [Foreman](https://github.com/ddollar/foreman) 的进程管理\n\n### 静态服务器\n\n双击一个 html 文件多半会看不了，经典的解决方案是 `python -m SimpleHTTPServer \u003cport\u003e`，\n然而 windows 并不预装 py，而且有时候我想侧边栏显示文件树，markdown 高亮，\n遇到学习文件夹自动播放并且在没有插耳机的情况下静音。\n以前自己挖了一个坑 [doc-viewer](https://github.com/at15/doc-viewer) 。\nAyi 里目前只实现了基本的静态服务器 `Ayi web static`（不要被 help 骗了，根本没有 highlight)。\n\n````\n⇒  Ayi web static -h\nserve static file like python's SimpleHTTPServer, support highlight and markdown render inspired by https://github.com/at15/doc-viewer\n\nUsage:\n  Ayi web static [flags]\n\nGlobal Flags:\n      --config string   config file (default is $HOME/.ayi.yaml)\n  -n, --dry-run         show commands to execute\n  -p, --port int        port to listen on (default 3000)\n      --root string     server root folder\n  -v, --verbose         verbose output\n````\n\n## 使用开源库中遇到的问题\n\n虽然我们要站在巨人的肩膀上，但是站的久了就会发现有些巨人其实也有点 low，比如\n\n- 不支持 windows 的 [overall](https://github.com/go-playground/overalls)，[fork](https://github.com/at15/overalls)\n- 不支持 ignore 的 [go.rice](https://github.com/GeertJohan/go.rice), [fork](https://github.com/at15/go.rice/tree/feature/ignore) 和 [issue](https://github.com/GeertJohan/go.rice/issues/83)\n- 不支持 filter 的 [logrus](https://github.com/sirupsen/logrus)，还自带[统计运行时间的 bug](https://github.com/sirupsen/logrus/issues/457)\n\n一些库虽然 star 很高，但是其实如果仔细看代码的话会发现很多问题，同时看别人的代码可以学到一些自己以前忽略的问题，比如 Golang 里 struct 的方法的 thread safe。\n相关的 issue [dyweb/Ayi#59](https://github.com/dyweb/Ayi/issues/59) [at15/go-learning#3](https://github.com/at15/go-learning/issues/3)。\nlogrus 里对应的代码如下，作为**读者的练习**。\n\n\u003c!-- TODO: no highlight --\u003e\n````golang\n// This function is not declared with a pointer value because otherwise\n// race conditions will occur when using multiple goroutines\nfunc (entry Entry) log(level Level, msg string) {\n        var buffer *bytes.Buffer\n\tentry.Time = time.Now()\n\tentry.Level = level\n\tentry.Message = msg\n````\n\n一些(很多)开源库都维护状态都是很不乐观的，上面提到的几个开 PR 和 Feature Request 的 issue\n都是没人鸟的，既然已经看了那么多了，为什么不自己写呢？ 所以就开始造轮子了(其实还是想造轮子)。\n\nbtw: 在使用开源项目的过程中完全没有必要去埋怨作者无视你的各种请求和贡献，换位思考一下，\n你是愿意陪妹子玩一晚上呢，还是愿意改 Gayhub 上某个不认识的人反馈的 bug 呢 (没有妹子的人表示思考不出来，我选择去改 bug)。\n\n## 通用库 (轮子)\n\n自己造轮子有以下几个优点:\n\n- 方便维护\n- 代码风格一致，比如 [spf13](https://github.com/spf13/) 的 [viper](https://github.com/spf13/viper) 和 [cobra](https://github.com/spf13/cobra/)\n- 可以共用很多 code base\n\n当然关键还是程序员的天性，上面的都是借口。\n\nAyi 里抽出来的库有以下几个\n\n### Log\n\nhttps://github.com/dyweb/Ayi/tree/master/common/log 仿照 [logrus](https://github.com/sirupsen/logrus) 实现,\n目标功能类似 log4j ([logback](http://logback.qos.ch/))\n\n有以下几个特点\n\n- 支持类似 log4j 的按照 package 进行 filter，避免了:\n  - 开启 debug 之后大量输出淹没了需要的信息\n  - 为了 debug，把代码里的 debug 改成 info，忘记改回去\n- 支持更多的 Level (你想加个 Hearbreak 什么的 Level 也可以 `log.Hearbreak(\"got a good man card on New Year's Eve\")`)\n- 减少了 lock (不过没做 benchmark)\n- 移除了 logger 上与 logEntry 重复的接口\n\n之后计划\n\n- 改用 generator 生成代码，`Debugf` 和其他所有 `*f` 都只差一个单词，为什么要人写呢 (我就不说我拼写错误然后 painc 了)。\n- 支持 log4j 的 appender, transformer, xml etc.\n\n### Runner\n\n之前在自动化的部分已经基本说过了，所以就不说了(就是想加个标题)。\n\n### Structure\n\nGolang 内置的数据结构少的可怜，作为一个用了3天 python 的人当然要加一点数据结构。\n\n目前实现的有\n\n- [Set](https://github.com/dyweb/Ayi/tree/common-util/runner/common/structure)\n(一开始只有 Contains 没有 Add 用了才发现这个 Set 是 immutable 的)。\n- 没有然后了\n\n### Requests\n\n`net/http` 很好用，但是 `python` 的 `requests` 更简洁，不过这个轮子目前在[另一项目(xephon-b)里](https://github.com/xephonhq/xephon-b/tree/master/pkg/util/requests)\n\nBefore\n\n````golang\nfunc (client *KairosDBHTTPClient) Ping() error {\n\tres, err := http.Get(client.Config.Host.HostURL() + \"/api/v1/version\")\n\tif err != nil {\n\t\tlog.Warn(\"can't get kairosdb version\")\n\t\tlog.Debug(err.Error())\n\t\treturn err\n\t}\n\tdefer res.Body.Close()\n\tresContent, err := ioutil.ReadAll(res.Body)\n\tif err != nil {\n\t\tlog.Warn(\"can't read response body\")\n\t\tlog.Debug(err.Error())\n\t\treturn err\n\t}\n\tvar resData map[string]string\n\tif err := json.Unmarshal(resContent, \u0026resData); err != nil {\n\t\tlog.Warn(\"can't parse json\")\n\t\tlog.Debug(err.Error())\n\t\treturn err\n\t}\n\tlog.Info(\"KairosDB version is \" + resData[\"version\"])\n\treturn nil\n}\n````\n\nAfter\n\n````golang\nfunc (client *KairosDBHTTPClient) Ping() error {\n\tversionURL := client.Config.Host.HostURL() + \"/api/v1/version\"\n\tres, err := requests.GetJSON(versionURL)\n\tif err != nil {\n\t\treturn errors.Wrapf(err, \"can't reach KairosDB via %s\", versionURL)\n\t}\n\tlog.Info(\"KairosDB version is \" + res[\"version\"])\n\treturn nil\n}\n````\n\n## 开发计划\n\n上面说了那么多，一半都是画饼，可以从 issue 里看最近的进度\n\n- [正在开发的部分](https://github.com/dyweb/Ayi/issues?q=is%3Aopen+is%3Aissue+label%3Aworking)\n- [想做但是被搁置了的 issue](https://github.com/dyweb/Ayi/issues?utf8=%E2%9C%93\u0026q=is%3Aissue%20label%3Abacklog)\n\n~~欢迎感兴趣的女同学联系我! 我的微信是 `uictor`~~\n\n预计等到国内寒假的时候很多坑可以填完了，到时候欢迎假期想了解一下 Golang 的小伙伴来玩，我会加 `help wanted` 和难度的 label。\n\n## 开发人员\n\n[GitHub 传送门](https://github.com/dyweb/Ayi/graphs/contributors)\n\n- 咩在项目开始时提交了一些 shell 脚本，但是由于转到了 Golang 以及咩一向很忙，遂弃婶\n- @kdplus (丘) 参与过 `Ayi check` 的开发，不过那时我 Golang 菜的抠脚，导致丘也在划水。\n- @gaocegege (策策) 因为周报的功能，参与过一段时间的开发，\n引入了`Godep` 交叉编译，不过最后周报的功能并没有投入实用。\n\n## 总结\n\n- 等有钱了，给大家都配 MBP\n- 自己开的坑，不能让别人填 (我去开个找妹子的坑先)\n\n## 杂项\n\n- 使用 `git log -reverse` 可以反过来看 log, 可以用来找第一个提交。\n- shell 在 windows 下基本不会有问题，因为为了使用 git，东岳所有的 windows 用户都安装了\nmsysgit (现在叫 git for windows)，它自带了 bash 和一些基本的工具。\n- 周报的功能作为 MOS 的一个项目交给了 @codeworm96, 进度见[这个issue](https://github.com/dyweb/mos/issues/1)\n- [所有带 `backlog` 标签的 issue](https://github.com/dyweb/Ayi/issues?q=is%3Aissue+label%3Abacklog+is%3Aclosed)\n\n第一个提交\n````\ncommit 19858fe3958317da08dc512116c58acbd82b2a35\nAuthor: At15 \u003cat15@outlook.com\u003e\nDate:   Sun Jul 26 13:24:38 2015 +0800\n\n    Initial commit\n````\n\n## 更新\n\n## 引用\n\n## 许可协议\n\n- 本文遵守[创作共享CC BY-NC-SA 3.0协议](https://creativecommons.org/licenses/by-nc-sa/3.0/cn/)\n- 网络平台转载请联系 \u003cmarketing@dongyue.io\u003e\n","cover":"","link":"ayi.html","preview":"\u003cp\u003eAyi 跨平台的命令行工具(库)\u003c/p\u003e\n","title":"Ayi"}]